# ğŸ¤– ØªÙ‚Ø±ÙŠØ± Ø´Ø§Ù…Ù„: Ù…Ù†Ø·Ù‚ Ø§Ù„Ø¨ÙˆØª ÙˆØ§Ù„Ø±Ø¯ÙˆØ¯ - Ø¬ÙˆÙ‡Ø± Ø§Ù„Ù…Ø´Ø±ÙˆØ¹

## ğŸ“‹ ÙÙ‡Ø±Ø³ Ø§Ù„ØªÙ‚Ø±ÙŠØ±
1. [Ù…Ø¹Ù…Ø§Ø±ÙŠØ© Ø§Ù„Ù†Ø¸Ø§Ù…](#1-Ù…Ø¹Ù…Ø§Ø±ÙŠØ©-Ø§Ù„Ù†Ø¸Ø§Ù…)
2. [Ø¯ÙˆØ±Ø© Ø­ÙŠØ§Ø© Ø§Ù„Ø±Ø³Ø§Ù„Ø© Ø§Ù„ÙƒØ§Ù…Ù„Ø©](#2-Ø¯ÙˆØ±Ø©-Ø­ÙŠØ§Ø©-Ø§Ù„Ø±Ø³Ø§Ù„Ø©)
3. [Ù†Ø¸Ø§Ù… Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ](#3-Ù†Ø¸Ø§Ù…-Ø§Ù„Ø°ÙƒØ§Ø¡-Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ)
4. [Ù…Ø­Ø±Ùƒ ÙÙ‡Ù… Ø§Ù„Ù„ØºØ©](#4-Ù…Ø­Ø±Ùƒ-ÙÙ‡Ù…-Ø§Ù„Ù„ØºØ©)
5. [Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ù…Ø¹Ø±ÙØ© ÙˆØ§Ù„Ø¨Ø­Ø«](#5-Ù‚Ø§Ø¹Ø¯Ø©-Ø§Ù„Ù…Ø¹Ø±ÙØ©)
6. [Ù†Ø¸Ø§Ù… Ø§Ù„Ø£ÙˆÙ„ÙˆÙŠØ§Øª](#6-Ù†Ø¸Ø§Ù…-Ø§Ù„Ø£ÙˆÙ„ÙˆÙŠØ§Øª)
7. [Ø§Ù„ØªØ­Ø³ÙŠÙ†Ø§Øª Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø©](#7-Ø§Ù„ØªØ­Ø³ÙŠÙ†Ø§Øª-Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø©)

---

## 1. Ù…Ø¹Ù…Ø§Ø±ÙŠØ© Ø§Ù„Ù†Ø¸Ø§Ù… ğŸ—ï¸

### 1.1 Ø§Ù„Ø·Ø¨Ù‚Ø§Øª Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           WIDGET (Frontend)                  â”‚
â”‚  â†“ User Message                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚
                   â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚      Chat Controller (Entry Point)           â”‚
â”‚  - Validation                                â”‚
â”‚  - Session Management                        â”‚
â”‚  - Request Handoff                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚
                   â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         Chat Service (Core Logic)            â”‚
â”‚  - Save Message                              â”‚
â”‚  - Conversation Management                   â”‚
â”‚  - History Retrieval (with cache)            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚
                   â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚      AI Service (Brain of Bot) ğŸ§            â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ 1. Business Context Loading         â”‚   â”‚
â”‚  â”‚ 2. Parallel Analysis (3 threads):   â”‚   â”‚
â”‚  â”‚    - Intent Detection               â”‚   â”‚
â”‚  â”‚    - Sentiment Analysis             â”‚   â”‚
â”‚  â”‚    - Dialect/Language Detection     â”‚   â”‚
â”‚  â”‚ 3. Vector Search (RAG)              â”‚   â”‚
â”‚  â”‚ 4. Prompt Construction              â”‚   â”‚
â”‚  â”‚ 5. Provider Selection (4-tier)      â”‚   â”‚
â”‚  â”‚ 6. Response Generation              â”‚   â”‚
â”‚  â”‚ 7. Analytics & Billing              â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 2. Ø¯ÙˆØ±Ø© Ø­ÙŠØ§Ø© Ø§Ù„Ø±Ø³Ø§Ù„Ø© ğŸ”„

### 2.1 Ø§Ù„Ù…Ø±Ø­Ù„Ø© 1: Ø§Ø³ØªÙ‚Ø¨Ø§Ù„ Ø§Ù„Ø±Ø³Ø§Ù„Ø©
**File**: `chat.controller.ts` â†’ `sendMessage()`

```typescript
// 1. Validation
SendMessageSchema.parse(req.body)
  â†“
// 2. Visitor Identity Resolution
resolveVisitorIdentity(visitorId, conversationId, sessionId)
  â†“
// 3. Save User Message to Database
chatService.saveMessage(businessId, conversationId, content, 'USER')
  â†“
// 4. Apply Pre-Chat Metadata (if exists)
applyPreChatMetadata(conversationId, visitorId, preChatData)
```

### 2.2 Ø§Ù„Ù…Ø±Ø­Ù„Ø© 2: Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø°ÙƒÙŠØ©
**File**: `ai.service.ts` â†’ `generateResponse()`

#### **Ø§Ù„Ø®Ø·ÙˆØ© 1: ØªØ­Ù…ÙŠÙ„ Ø³ÙŠØ§Ù‚ Ø§Ù„Ø¹Ù…Ù„**
```typescript
const business = await prisma.business.findUnique({
  where: { id: businessId },
  include: { 
    knowledgeBase: true,          // Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ù…Ø¹Ø±ÙØ©
    customAIModels: true           // Ù†Ù…Ø§Ø°Ø¬ AI Ù…Ø®ØµØµØ©
  }
});
```

**Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ø­Ù…Ù„Ø©:**
- `business.name`: Ø§Ø³Ù… Ø§Ù„Ø´Ø±ÙƒØ©
- `business.botTone`: Ù†Ø¨Ø±Ø© Ø§Ù„Ø±Ø¯ (friendly, professional, formal)
- `business.language`: Ø§Ù„Ù„ØºØ© Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ© (ar, en, ...)
- `business.systemPrompt`: Prompt Ù…Ø®ØµØµ (Ø§Ø®ØªÙŠØ§Ø±ÙŠ)
- `business.aiProviderConfig`: Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª AI Ø§Ù„Ù…Ø®ØµØµØ©

#### **Ø§Ù„Ø®Ø·ÙˆØ© 2: Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…ÙˆØ§Ø²ÙŠ (Parallel Processing)**
```typescript
const [intentResult, sentimentResult, dialectResult] = await Promise.all([
  intentDetectionService.detectIntent(userMessage),       // ÙƒØ´Ù Ø§Ù„Ù†ÙŠØ©
  sentimentAnalysisService.analyzeSentiment(userMessage), // ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ø´Ø§Ø¹Ø±
  dialectService.detectDialect(userMessage, { country })  // ÙƒØ´Ù Ø§Ù„Ù„Ù‡Ø¬Ø©
]);
```

**ğŸ“Š Intent Detection (ÙƒØ´Ù Ø§Ù„Ù†ÙŠØ©):**
- **File**: `intent-detection.service.ts`
- **Method**: Bayes Classifier (natural.js)
- **Intents Ø§Ù„Ù…Ø¯Ø¹ÙˆÙ…Ø©:**
  - `greeting`: ØªØ­ÙŠØ© (Ù…Ø±Ø­Ø¨Ø§ØŒ Ø§Ù„Ø³Ù„Ø§Ù… Ø¹Ù„ÙŠÙƒÙ…)
  - `inquiry`: Ø§Ø³ØªÙØ³Ø§Ø± (Ù…Ø§ØŒ Ù…ØªÙ‰ØŒ Ø£ÙŠÙ†ØŒ ÙƒÙŠÙ)
  - `complaint`: Ø´ÙƒÙˆÙ‰ (Ù…Ø´ÙƒÙ„Ø©ØŒ Ø¹Ø·Ù„ØŒ Ø®Ø·Ø£)
  - `purchase`: Ø´Ø±Ø§Ø¡ (Ø³Ø¹Ø±ØŒ Ø·Ù„Ø¨ØŒ Ø¯ÙØ¹)
  - `support`: Ø¯Ø¹Ù… (Ù…Ø³Ø§Ø¹Ø¯Ø©ØŒ Ø³Ø§Ø¹Ø¯Ù†ÙŠ)
  - `feedback`: Ø±Ø£ÙŠ (Ø§Ù‚ØªØ±Ø§Ø­ØŒ ØªØ­Ø³ÙŠÙ†)
  - `farewell`: ÙˆØ¯Ø§Ø¹ (Ù…Ø¹ Ø§Ù„Ø³Ù„Ø§Ù…Ø©ØŒ Ø´ÙƒØ±Ø§Ù‹)
  - `cancellation`: Ø¥Ù„ØºØ§Ø¡ (Ø¥Ù„ØºØ§Ø¡ØŒ ØªÙˆÙ‚Ù)

**Output:**
```json
{
  "intent": "complaint",
  "confidence": 0.85,
  "entities": ["order_number", "product_name"]
}
```

**ğŸ˜Š Sentiment Analysis (ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ø´Ø§Ø¹Ø±):**
- **File**: `sentiment-analysis.service.ts`
- **Method**: AFINN Sentiment Analyzer
- **Output:**
```json
{
  "sentiment": "NEGATIVE",
  "confidence": 0.78,
  "intensity": 0.65,
  "emotions": {
    "anger": 0.4,
    "sadness": 0.3,
    "joy": 0.0
  },
  "keywords": ["problem", "broken", "not working"]
}
```

**ğŸŒ Dialect Detection (ÙƒØ´Ù Ø§Ù„Ù„Ù‡Ø¬Ø©):**
- **File**: `dialect.service.ts`
- **Methods**: 
  1. **Keyword-based** (50+ ÙƒÙ„Ù…Ø© Ù„ÙƒÙ„ Ù„Ù‡Ø¬Ø©)
  2. **Geo-boost** (Ù…Ù† IP/Country)
  3. **Hybrid** (Ø¯Ù…Ø¬ Ø§Ù„Ø·Ø±ÙŠÙ‚ØªÙŠÙ†)

**Ø§Ù„Ù„Ù‡Ø¬Ø§Øª Ø§Ù„Ù…Ø¯Ø¹ÙˆÙ…Ø©:**
- `eg`: Ù…ØµØ±ÙŠ (Ø¹Ø§ÙŠØ²ØŒ Ù‚ÙˆÙŠØŒ Ø£ÙˆÙŠ)
- `sa`: Ø³Ø¹ÙˆØ¯ÙŠ (Ø§Ø¨ÙŠØŒ ÙƒØ°Ø§ØŒ Ø²ÙŠÙ†)
- `ae`: Ø¥Ù…Ø§Ø±Ø§ØªÙŠ (Ø´Ø­Ø§Ù„ÙƒØŒ ÙƒÙŠÙÙƒ)
- `kw`: ÙƒÙˆÙŠØªÙŠ (Ø´Ù„ÙˆÙ†ÙƒØŒ ÙˆØ§ÙŠØ¯)
- `gulf`: Ø®Ù„ÙŠØ¬ÙŠ Ø¹Ø§Ù…
- `lev`: Ø´Ø§Ù…ÙŠ (Ø´ÙˆØŒ Ù‡Ù„Ø£ØŒ ÙƒÙŠÙÙƒ)
- `maghreb`: Ù…ØºØ§Ø±Ø¨ÙŠ (ÙƒÙŠÙØ§Ø´ØŒ Ø¨Ø²Ø§Ù)
- `msa`: Ø¹Ø±Ø¨ÙŠØ© ÙØµØ­Ù‰

**Output:**
```json
{
  "dialect": "eg",
  "confidence": 0.82,
  "method": "hybrid"
}
```

#### **Ø§Ù„Ø®Ø·ÙˆØ© 3: Ø§Ù„Ø¨Ø­Ø« ÙÙŠ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ù…Ø¹Ø±ÙØ© (RAG)**
**File**: `vector-search.service.ts`

**Ø§Ù„ØªØ¯ÙÙ‚:**
```
1. Generate Embedding Ù„Ù„Ø³Ø¤Ø§Ù„
   â†“ (embedding.service.ts)
2. Vector Search ÙÙŠ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª (pgvector)
   â†“ (SELECT ... ORDER BY embedding <=> query)
3. Reranking Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Voyage AI
   â†“ (Ø¥Ø¹Ø§Ø¯Ø© ØªØ±ØªÙŠØ¨ Ø­Ø³Ø¨ Ø§Ù„ØµÙ„Ø© Ø§Ù„Ø­Ù‚ÙŠÙ‚ÙŠØ©)
4. Filtering (minSimilarity >= 0.7)
   â†“
5. Return Top 5 Results
```

**Ù…Ø«Ø§Ù„ Output:**
```json
[
  {
    "id": "chunk_123",
    "content": "Ø£Ø³Ø¹Ø§Ø±Ù†Ø§ ØªØ¨Ø¯Ø£ Ù…Ù† 100 Ø±ÙŠØ§Ù„ Ø´Ù‡Ø±ÙŠØ§Ù‹...",
    "similarity": 0.89,
    "rerank_score": 0.92
  },
  {
    "id": "chunk_456",
    "content": "Ø§Ù„Ø¯Ø¹Ù… Ø§Ù„ÙÙ†ÙŠ Ù…ØªØ§Ø­ 24/7...",
    "similarity": 0.76,
    "rerank_score": 0.81
  }
]
```

#### **Ø§Ù„Ø®Ø·ÙˆØ© 4: Ø¨Ù†Ø§Ø¡ System Prompt**
```typescript
let systemPrompt = `You are an intelligent AI assistant for ${business.name}.

**Business Context:**
- Name: Faheemly
- Tone: professional
- Language: ar

**User Context:**
- Intent: complaint
- Sentiment: NEGATIVE (Confidence: 78%)
- Dialect: eg (Confidence: 82%, Method: hybrid)
- Entities: order_number, product_name

**Instructions:**
1. Respond in eg dialect/language
2. Use a professional tone
3. Be helpful, accurate, and concise
4. If you don't know the answer, say so clearly
5. Show empathy and offer solutions        â† Ù„Ø£Ù† Intent = complaint
6. Be extra supportive and understanding    â† Ù„Ø£Ù† Sentiment = NEGATIVE
7. Match the user's detected dialect (eg)

**Relevant Knowledge Base:**
[1] (Relevance: 92.0%)
Ø£Ø³Ø¹Ø§Ø±Ù†Ø§ ØªØ¨Ø¯Ø£ Ù…Ù† 100 Ø±ÙŠØ§Ù„ Ø´Ù‡Ø±ÙŠØ§Ù‹ ÙˆÙŠÙ…ÙƒÙ†Ùƒ Ø§Ù„Ø§Ø´ØªØ±Ø§Ùƒ Ø¹Ø¨Ø± Ø§Ù„Ù…ÙˆÙ‚Ø¹...

[2] (Relevance: 81.0%)
Ø§Ù„Ø¯Ø¹Ù… Ø§Ù„ÙÙ†ÙŠ Ù…ØªØ§Ø­ 24/7 Ø¹Ø¨Ø± Ø§Ù„ÙˆØ§ØªØ³Ø§Ø¨ ÙˆØ§Ù„Ø¨Ø±ÙŠØ¯ Ø§Ù„Ø¥Ù„ÙƒØªØ±ÙˆÙ†ÙŠ...

Use this information to answer the user's question accurately.`;
```

#### **Ø§Ù„Ø®Ø·ÙˆØ© 5: Ø§Ø®ØªÙŠØ§Ø± Provider (4-Tier Strategy)**
```typescript
// Priority 1: Custom AI Models (Ù…Ù† Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª)
if (business.customAIModels.length > 0) {
  provider = new CustomAIProvider(customModel.config);
  providerType = `custom:${customModel.name}`;
}

// Priority 2: aiProviderConfig (Ù…Ù† Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Business)
if (!provider) {
  provider = this.providers.get(config?.type || 'groq');
}

// Priority 3: Groq Fallback
if (!provider) {
  provider = this.providers.get('groq');
}

// Priority 4: Gemini Last Resort
if (!provider) {
  provider = this.providers.get('gemini');
}
```

**Ø§Ù„Ù€ Providers Ø§Ù„Ù…Ø¯Ø¹ÙˆÙ…Ø©:**
1. **Custom AI** (OpenAI-compatible APIs)
2. **Groq** - Model: `llama-3.1-8b-instant` (560 tps)
3. **Gemini** - Model: `gemini-2.0-flash-exp`

#### **Ø§Ù„Ø®Ø·ÙˆØ© 6: ØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ø±Ø¯**
```typescript
const { response, usage } = await provider.generateResponse(
  `${systemPrompt}\n\nUser: ${userMessage}`,
  { model: modelConfig?.model }
);
```

#### **Ø§Ù„Ø®Ø·ÙˆØ© 7: Analytics & Billing**
```typescript
// Async Billing Update (Ù„Ø§ ÙŠÙ†ØªØ¸Ø±)
prisma.business.update({
  where: { id: businessId },
  data: { messagesUsed: { increment: 1 } }
}).catch(console.error);

// Log Analytics
logger.info('AI Response Generated:', {
  businessId,
  provider: 'groq',
  tokensUsed: 245,
  intent: 'complaint',
  sentiment: 'NEGATIVE',
  dialect: 'eg',
  dialectConfidence: 0.82
});
```

### 2.3 Ø§Ù„Ù…Ø±Ø­Ù„Ø© 3: Ø­ÙØ¸ Ø§Ù„Ø±Ø¯
```typescript
const botMessage = await chatService.saveMessage(
  businessId,
  conversationId,
  aiResponse,
  'BOT'
);
```

### 2.4 Ø§Ù„Ù…Ø±Ø­Ù„Ø© 4: Ø¥Ø±Ø³Ø§Ù„ Ù„Ù„Ø¹Ù…ÙŠÙ„
```typescript
return res.json({
  conversationId,
  userMessage: { id, content, sender, createdAt },
  botMessage: { id, content, sender, createdAt },
  content: aiResponse  // Legacy compatibility
});
```

---

## 3. Ù†Ø¸Ø§Ù… Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ ğŸ§ 

### 3.1 Ù…Ù‚Ø¯Ù…ÙŠ Ø§Ù„Ø®Ø¯Ù…Ø© (AI Providers)

#### **GroqProvider**
```typescript
class GroqProvider implements AIProvider {
  private client: Groq;
  
  async generateResponse(prompt: string, options?: any) {
    const completion = await this.client.chat.completions.create({
      messages: [{ role: 'user', content: prompt }],
      model: 'llama-3.1-8b-instant',  // âš ï¸ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„ÙˆØ­ÙŠØ¯ Ø§Ù„Ù…Ø¯Ø¹ÙˆÙ… Ø­Ø§Ù„ÙŠØ§Ù‹
    });
    return {
      response: completion.choices[0]?.message?.content || '',
      usage: { tokens: completion.usage?.total_tokens || 0 }
    };
  }
}
```

**Ø§Ù„Ù…Ù…ÙŠØ²Ø§Øª:**
- âœ… Ø³Ø±Ø¹Ø© ÙØ§Ø¦Ù‚Ø©: 560 tokens/sec
- âœ… Ù…Ø¬Ø§Ù†ÙŠ Ù„Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ù…Ø¹ØªØ¯Ù„
- âŒ Ù…Ø­Ø¯ÙˆØ¯ Ø¨Ù€ 8B parameters (Ø£Ù‚Ù„ Ø°ÙƒØ§Ø¡Ù‹ Ù…Ù† 70B)

#### **GeminiProvider**
```typescript
class GeminiProvider implements AIProvider {
  async generateResponse(prompt: string, options?: any) {
    const model = this.client.getGenerativeModel({ 
      model: 'gemini-2.0-flash-exp' 
    });
    const result = await model.generateContent(prompt);
    return {
      response: result.response.text(),
      usage: { tokens: 0 }
    };
  }
}
```

**Ø§Ù„Ù…Ù…ÙŠØ²Ø§Øª:**
- âœ… Ù†Ù…ÙˆØ°Ø¬ Ø­Ø¯ÙŠØ« (2.0 Flash)
- âœ… Fallback Ù‚ÙˆÙŠ
- âš ï¸ Experimental (Ù‚Ø¯ ÙŠØªØºÙŠØ±)

#### **CustomAIProvider**
```typescript
class CustomAIProvider implements AIProvider {
  async generateResponse(prompt: string, options?: any) {
    const response = await axios.post(
      endpoint,  // Ù…Ù† config
      {
        model: config.model,
        messages: [{ role: 'user', content: prompt }],
        temperature: config.temperature || 0.7,
        max_tokens: config.maxTokens || 2000
      },
      {
        headers: {
          'Authorization': `Bearer ${config.apiKey}`,
          'Content-Type': 'application/json'
        }
      }
    );
    return {
      response: response.data.choices[0]?.message?.content,
      usage: { tokens: response.data.usage?.total_tokens || 0 }
    };
  }
}
```

**Ø§Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù…:**
- ÙŠØ¯Ø¹Ù… Ø£ÙŠ API Ù…ØªÙˆØ§ÙÙ‚ Ù…Ø¹ OpenAI
- ÙŠÙØ®Ø²Ù† ÙÙŠ `business.customAIModels` ÙÙŠ DB
- Ù„Ù‡ Ø§Ù„Ø£ÙˆÙ„ÙˆÙŠØ© Ø§Ù„Ø£ÙˆÙ„Ù‰ ÙÙŠ Ø§Ù„Ø§Ø®ØªÙŠØ§Ø±

---

## 4. Ù…Ø­Ø±Ùƒ ÙÙ‡Ù… Ø§Ù„Ù„ØºØ© ğŸ—£ï¸

### 4.1 Intent Detection (ÙƒØ´Ù Ø§Ù„Ù†ÙŠØ©)

**Ø§Ù„Ø®ÙˆØ§Ø±Ø²Ù…ÙŠØ©:** Naive Bayes Classifier

**Ø§Ù„ØªØ¯Ø±ÙŠØ¨:**
```typescript
constructor() {
  this.classifier = new natural.BayesClassifier();
  
  // Training Data
  this.intents.set('complaint', [
    'problem', 'issue', 'not working', 'broken', 'error',
    'Ù…Ø´ÙƒÙ„Ø©', 'Ø®Ø·Ø£', 'Ù„Ø§ ÙŠØ¹Ù…Ù„', 'Ø¹Ø·Ù„'
  ]);
  
  // Train
  this.intents.forEach((samples, intent) => {
    samples.forEach(sample => {
      this.classifier.addDocument(sample, intent);
    });
  });
  this.classifier.train();
}
```

**Ø§Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù…:**
```typescript
detectIntent(text: string): Intent {
  const classifications = this.classifier.getClassifications(text);
  const topClassification = classifications[0];
  
  return {
    intent: topClassification.label,
    confidence: topClassification.value,
    entities: this.extractEntities(text)
  };
}
```

### 4.2 Sentiment Analysis (ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ø´Ø§Ø¹Ø±)

**Ø§Ù„Ø®ÙˆØ§Ø±Ø²Ù…ÙŠØ©:** AFINN Sentiment Analyzer

```typescript
async analyzeSentiment(text: string): Promise<SentimentResult> {
  const tokens = this.tokenizer.tokenize(text.toLowerCase());
  const score = this.analyzer.getSentiment(tokens);  // -1 to +1
  
  // Determine sentiment
  let sentiment: 'POSITIVE' | 'NEGATIVE' | 'NEUTRAL';
  if (score > 0.1) sentiment = 'POSITIVE';
  else if (score < -0.1) sentiment = 'NEGATIVE';
  else sentiment = 'NEUTRAL';
  
  // Calculate confidence & intensity
  const confidence = Math.min(Math.abs(score) * 2, 1.0);
  const intensity = Math.min(Math.abs(score), 1.0);
  
  // Detect emotions
  const emotions = {
    joy: this.countWords(tokens, joyWords) / tokens.length,
    anger: this.countWords(tokens, angerWords) / tokens.length,
    sadness: this.countWords(tokens, sadnessWords) / tokens.length,
    fear: this.countWords(tokens, fearWords) / tokens.length,
    surprise: this.countWords(tokens, surpriseWords) / tokens.length
  };
  
  return { sentiment, confidence, intensity, emotions };
}
```

### 4.3 Dialect Detection (ÙƒØ´Ù Ø§Ù„Ù„Ù‡Ø¬Ø©)

**Ø§Ù„Ø·Ø±ÙŠÙ‚Ø© Ø§Ù„Ù‡Ø¬ÙŠÙ†Ø©:** Keyword + Geo-boost

```typescript
async detectDialect(text: string, options?: { country?: string }): Promise<DialectDetectionResult> {
  // Step 1: Keyword Detection
  const keywordResult = this.detectByKeywords(text);
  
  // Step 2: Geo-boost (if country provided)
  if (options?.country && this.countryToDialect[options.country]) {
    const geoDialect = this.countryToDialect[options.country];
    
    // Low confidence? Use geo
    if (keywordResult.confidence < 0.7) {
      return {
        dialect: geoDialect,
        confidence: Math.min(keywordResult.confidence + 0.2, 0.85),
        method: 'hybrid'
      };
    }
    
    // Match? Boost confidence
    if (keywordResult.dialect === geoDialect) {
      keywordResult.confidence += 0.15;
      keywordResult.method = 'hybrid';
    }
  }
  
  return keywordResult;
}

private detectByKeywords(text: string): DialectDetectionResult {
  const lowerText = text.toLowerCase();
  let bestMatch = { dialect: 'msa', confidence: 0.5, score: 0 };
  
  for (const [dialect, { words, weight }] of Object.entries(this.dialectKeywords)) {
    const matches = words.filter(w => lowerText.includes(w)).length;
    if (matches === 0) continue;
    
    // Scoring: (matches / total) * weight * length_factor
    const textLengthFactor = Math.min(lowerText.split(' ').length / 10, 1.5);
    const score = (matches / words.length) * weight * textLengthFactor;
    
    if (score > bestMatch.score) {
      const confidence = Math.min(0.6 + (score * 0.35), 0.92);
      bestMatch = { dialect, confidence, score };
    }
  }
  
  return { dialect: bestMatch.dialect, confidence: bestMatch.confidence, method: 'keyword' };
}
```

**Ù…Ø«Ø§Ù„ Ø¹Ù…Ù„ÙŠ:**
```javascript
// Input
detectDialect("Ø¹Ø§ÙŠØ² Ø£Ø·Ù„Ø¨ Ù…Ù†ØªØ¬ Ù‚ÙˆÙŠ Ø£ÙˆÙŠ", { country: 'EG' })

// Process
// 1. Keyword: Ø¹Ø§ÙŠØ² (eg), Ù‚ÙˆÙŠ (eg), Ø£ÙˆÙŠ (eg) â†’ 3 matches
// 2. Score: (3/50) * 1.2 * 1.0 = 0.072
// 3. Confidence: 0.6 + (0.072 * 0.35) = 0.625
// 4. Geo-boost: EG matches â†’ +0.15 = 0.775

// Output
{
  dialect: 'eg',
  confidence: 0.775,
  method: 'hybrid'
}
```

---

## 5. Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ù…Ø¹Ø±ÙØ© (RAG System) ğŸ“š

### 5.1 Embedding Generation

**File**: `embedding.service.ts`

**Providers (Ø¨Ø§Ù„Ø£ÙˆÙ„ÙˆÙŠØ©):**
1. **Voyage AI** (Ø§Ù„Ø£ÙØ¶Ù„)
   - Model: `voyage-multilingual-2`
   - Dimensions: 1024
   - Endpoint: `https://api.voyageai.com/v1/embeddings`

2. **OpenAI** (Fallback)
   - Model: `text-embedding-3-small`
   - Dimensions: 1536
   - Endpoint: `https://api.openai.com/v1/embeddings`

3. **Groq** (Fallback 2)
   - Model: `nomic-embed-text-v1.5`
   - Dimensions: 768
   - Endpoint: `https://api.groq.com/openai/v1/embeddings`

**Ø§Ù„ØªØ¯ÙÙ‚:**
```typescript
async generateEmbedding(text: string): Promise<EmbeddingResponse> {
  // 1. Check Cache
  const cached = await cacheService.get(`embedding:${text.substring(0, 100)}`);
  if (cached) return { embedding: cached, provider: 'cache' };
  
  // 2. Select Provider (Voyage â†’ OpenAI â†’ Groq)
  const provider = this.providers.get('VOYAGE') || this.providers.get('OPENAI');
  
  // 3. Generate
  const response = await axios.post(provider.endpoint, {
    input: text,
    model: provider.model
  }, {
    headers: { 'Authorization': `Bearer ${provider.apiKey}` }
  });
  
  const embedding = response.data.data[0].embedding;
  
  // 4. Cache (24 hours)
  await cacheService.set(`embedding:${text.substring(0, 100)}`, embedding, 86400);
  
  return { embedding, provider: 'VOYAGE' };
}
```

### 5.2 Vector Search

**File**: `vector-search.service.ts`

**SQL Query (pgvector):**
```sql
SELECT 
  id,
  "knowledgeBaseId",
  content,
  metadata,
  1 - (embedding <=> $queryEmbedding::vector) as similarity
FROM "KnowledgeChunk"
WHERE "businessId" = $businessId
ORDER BY embedding <=> $queryEmbedding::vector
LIMIT $limit
```

**Ø§Ù„Ù…Ø³Ø§ÙØ© Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…Ø©:** Cosine Distance (`<=>`)

### 5.3 Reranking

**Ø§Ù„Ù‡Ø¯Ù:** ØªØ­Ø³ÙŠÙ† Ø¯Ù‚Ø© Ø§Ù„Ù†ØªØ§Ø¦Ø¬ Ø¨Ø¹Ø¯ Vector Search

**Ø§Ù„Ø·Ø±Ù‚:**
1. **Voyage AI Rerank** (Ø¥Ø°Ø§ Ù…ØªÙˆÙØ±)
```typescript
const response = await axios.post(
  'https://api.voyageai.com/v1/rerank',
  {
    model: 'rerank-2-lite',
    query: query,
    documents: results.map(r => r.content)
  }
);
```

2. **Local Reranking** (Fallback)
```typescript
const scored = results.map(result => {
  let boost = 1.0;
  
  // Exact match boost
  if (content.toLowerCase().includes(query.toLowerCase())) {
    boost = 1.5;
  }
  
  // Word overlap score
  const queryWords = query.toLowerCase().split(/\s+/);
  const contentWords = new Set(content.toLowerCase().split(/\s+/));
  const overlap = queryWords.filter(w => contentWords.has(w)).length;
  const overlapScore = overlap / queryWords.length;
  
  const finalScore = result.similarity * boost * (1 + overlapScore);
  
  return { ...result, rerank_score: finalScore };
});
```

### 5.4 Hybrid Search

```typescript
async hybridSearch(query: string, businessId: string, limit: number = 5): Promise<any[]> {
  // 1. Vector Search
  const vectorResults = await this.searchKnowledge(query, businessId, limit);
  
  // 2. Rerank
  const reranked = await this.rerankResults(query, vectorResults);
  
  return reranked;
}
```

---

## 6. Ù†Ø¸Ø§Ù… Ø§Ù„Ø£ÙˆÙ„ÙˆÙŠØ§Øª âš¡

### 6.1 Ø£ÙˆÙ„ÙˆÙŠØ© Providers

```
1. Custom AI Models (Ø¥Ø°Ø§ Ù…ÙˆØ¬ÙˆØ¯Ø© ÙÙŠ DB)
   â†“ (health check failed?)
2. aiProviderConfig (Ù…Ù† Business settings)
   â†“ (unavailable?)
3. Groq (Default fallback)
   â†“ (unavailable?)
4. Gemini (Last resort)
   â†“ (unavailable?)
âŒ Error: No providers available
```

### 6.2 Ø£ÙˆÙ„ÙˆÙŠØ© Cache

**Ø§Ù„Ø£Ù…Ø§ÙƒÙ† Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…Ø©:**
1. **Conversation History** (5 Ø¯Ù‚Ø§Ø¦Ù‚)
   - Key: `conversation:${id}:history`
   
2. **Knowledge Search** (1 Ø³Ø§Ø¹Ø©)
   - Key: `knowledge:${businessId}:${queryHash}`
   
3. **Embeddings** (24 Ø³Ø§Ø¹Ø©)
   - Key: `embedding:${text.substring(0,100)}`

### 6.3 Ø£ÙˆÙ„ÙˆÙŠØ© Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©

**Parallel Processing:**
```typescript
// Ù‡Ø°Ù‡ Ø§Ù„Ø¹Ù…Ù„ÙŠØ§Øª ØªØªÙ… Ø¨Ø§Ù„ØªÙˆØ§Ø²ÙŠ (Ù„Ø§ ØªÙ†ØªØ¸Ø± Ø¨Ø¹Ø¶Ù‡Ø§)
await Promise.all([
  intentDetection,      // ~50ms
  sentimentAnalysis,    // ~30ms
  dialectDetection      // ~20ms
]);
```

**Sequential Processing:**
```typescript
// Ù‡Ø°Ù‡ Ø§Ù„Ø¹Ù…Ù„ÙŠØ§Øª ØªØªÙ… Ø¨Ø§Ù„ØªØ³Ù„Ø³Ù„ (ØªÙ†ØªØ¸Ø± Ø¨Ø¹Ø¶Ù‡Ø§)
1. Load Business Context      // ~20ms
2. Parallel Analysis          // ~50ms
3. Vector Search              // ~200ms
4. Prompt Construction        // ~5ms
5. AI Response Generation     // ~500-2000ms
6. Save to Database          // ~30ms
```

---

## 7. Ø§Ù„ØªØ­Ø³ÙŠÙ†Ø§Øª Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø© ğŸš€

### 7.1 Ù…Ø´Ø§ÙƒÙ„ Ø­Ø±Ø¬Ø© âš ï¸

#### **Problem 1: Ù†Ù…ÙˆØ°Ø¬ Groq Ù…Ø­Ø¯ÙˆØ¯**
```
âŒ Current: llama-3.1-8b-instant (8B parameters)
   - Ø°ÙƒØ§Ø¡ Ù…Ø­Ø¯ÙˆØ¯
   - Ø±Ø¯ÙˆØ¯ Ù‚ØµÙŠØ±Ø©
   - ØµØ¹ÙˆØ¨Ø© ÙÙŠ Ø§Ù„Ø³ÙŠØ§Ù‚ Ø§Ù„Ø·ÙˆÙŠÙ„

âœ… Solution: ØªØ±Ù‚ÙŠØ© Ø¥Ù„Ù‰ Ù†Ù…ÙˆØ°Ø¬ Ø£Ù‚ÙˆÙ‰
   Option 1: llama-3.3-70b-versatile (Ø¥Ø°Ø§ Ø¹Ø§Ø¯)
   Option 2: openai/gpt-oss-120b (Ù…Ø¯ÙÙˆØ¹ØŒ 120B parameters)
   Option 3: Custom Model Ù…Ù† OpenAI/Anthropic
```

#### **Problem 2: Vector Search ÙŠÙØ´Ù„ Ø£Ø­ÙŠØ§Ù†Ø§Ù‹**
```
âŒ Error: "Vector search failed"
   Root Cause: pgvector extension ØºÙŠØ± Ù…ÙØ¹Ù‘Ù„ Ø£Ùˆ embedding NULL

âœ… Solution:
   1. Ø§Ù„ØªØ£ÙƒØ¯ Ù…Ù† pgvector extension:
      CREATE EXTENSION IF NOT EXISTS vector;
   
   2. Migration Ù„Ø¥Ø¶Ø§ÙØ© embeddings:
      ALTER TABLE "KnowledgeChunk" 
      ADD COLUMN IF NOT EXISTS embedding vector(1024);
   
   3. Re-index existing knowledge:
      npm run reindex-knowledge
```

#### **Problem 3: Dialect Detection Ø¯Ù‚Ø© 60% ÙÙ‚Ø·**
```
âŒ Current: 60-65% accuracy
   - ÙŠØ¹ØªÙ…Ø¯ Ø¹Ù„Ù‰ keywords ÙÙ‚Ø·
   - Ù…ÙØ±Ø¯Ø§Øª Ù…Ø­Ø¯ÙˆØ¯Ø© (50 ÙƒÙ„Ù…Ø©/Ù„Ù‡Ø¬Ø©)

âœ… Solution:
   1. Ø¥Ø¶Ø§ÙØ© ML Model (fastText/BERT):
      - Training Ø¹Ù„Ù‰ 100K+ Ø¹ÙŠÙ†Ø©
      - Ø¯Ù‚Ø© Ù…ØªÙˆÙ‚Ø¹Ø©: 85%+
   
   2. ØªÙˆØ³ÙŠØ¹ Keywords:
      - 200+ ÙƒÙ„Ù…Ø© Ù„ÙƒÙ„ Ù„Ù‡Ø¬Ø©
      - Ø¹Ø¨Ø§Ø±Ø§Øª Ø´Ø§Ø¦Ø¹Ø©
   
   3. Context-aware Detection:
      - Ø§Ø³ØªØ®Ø¯Ø§Ù… ØªØ§Ø±ÙŠØ® Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø©
      - ØªØ¹Ù„Ù… Ù…Ù† ØªÙØ¶ÙŠÙ„Ø§Øª Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…
```

### 7.2 ØªØ­Ø³ÙŠÙ†Ø§Øª Ø§Ù„Ø£Ø¯Ø§Ø¡ ğŸï¸

#### **Optimization 1: Response Time**
```
Current Average: 2-3 seconds
Target: < 1 second

Actions:
1. âœ… Cache embeddings (done)
2. âœ… Parallel processing (done)
3. â³ Streaming responses:
   - Ø¥Ø±Ø³Ø§Ù„ Ø§Ù„Ø±Ø¯ ÙƒÙ„Ù…Ø© Ø¨ÙƒÙ„Ù…Ø©
   - ØªØ­Ø³ÙŠÙ† ØªØ¬Ø±Ø¨Ø© Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…
   
4. â³ Edge caching:
   - Common questions cached at CDN
   - Instant responses Ù„Ù„Ø£Ø³Ø¦Ù„Ø© Ø§Ù„Ø´Ø§Ø¦Ø¹Ø©
```

#### **Optimization 2: Cost Reduction**
```
Current Cost/1K msgs: ~$2-5 (Ø­Ø³Ø¨ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬)

Actions:
1. Smart caching:
   - Cache similar questions (fuzzy match)
   - Reduce API calls by 40%

2. Prompt optimization:
   - Shorter prompts
   - Essential context only
   - Save 30% tokens

3. Tiered models:
   - Simple questions â†’ 8B model (cheap)
   - Complex questions â†’ 70B model (expensive)
```

### 7.3 Ù…ÙŠØ²Ø§Øª Ù…Ù‚ØªØ±Ø­Ø© âœ¨

#### **Feature 1: Context Memory**
```typescript
// Ø­ÙØ¸ Ø³ÙŠØ§Ù‚ Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø© Ø¨Ø°ÙƒØ§Ø¡
interface ConversationContext {
  userId: string;
  preferences: {
    dialect: string;
    topics: string[];
    tone: string;
  };
  history: {
    summary: string;           // Ù…Ù„Ø®Øµ Ø¢Ø®Ø± 10 Ø±Ø³Ø§Ø¦Ù„
    entities: Record<string, any>; // Ø§Ù„Ø£Ø´ÙŠØ§Ø¡ Ø§Ù„Ù…Ø°ÙƒÙˆØ±Ø©
    intent_history: string[];   // Ø§Ù„Ù†ÙˆØ§ÙŠØ§ Ø§Ù„Ø³Ø§Ø¨Ù‚Ø©
  };
}

// Ø§Ø³ØªØ®Ø¯Ø§Ù… ÙÙŠ Prompt
const context = await getConversationContext(conversationId);
systemPrompt += `\n\n**Conversation Context:**
- User prefers ${context.preferences.dialect} dialect
- Previous topics: ${context.history.topics.join(', ')}
- Summary: ${context.history.summary}
`;
```

#### **Feature 2: Multi-turn Conversations**
```typescript
// ØªØªØ¨Ø¹ Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø§Øª Ù…ØªØ¹Ø¯Ø¯Ø© Ø§Ù„Ø¯ÙˆØ±Ø§Øª
interface MultiTurnState {
  current_step: number;
  total_steps: number;
  collected_data: Record<string, any>;
  next_question: string;
}

// Ù…Ø«Ø§Ù„: Ø­Ø¬Ø² Ù…ÙˆØ¹Ø¯
// Turn 1: "Ø¹Ø§ÙŠØ² Ø£Ø­Ø¬Ø² Ù…ÙˆØ¹Ø¯"
// Bot: "ØªÙ…Ø§Ù…ØŒ Ø¥ÙŠÙ‡ Ø§Ù„ØªØ§Ø±ÙŠØ® Ø§Ù„Ù…Ù†Ø§Ø³Ø¨ Ù„ÙŠÙƒØŸ"
// Turn 2: "ÙŠÙˆÙ… Ø§Ù„Ø³Ø¨Øª"
// Bot: "Ø£ÙŠ Ø³Ø§Ø¹Ø© ØªÙØ¶Ù„ØŸ"
// Turn 3: "Ø§Ù„Ø³Ø§Ø¹Ø© 3 Ø§Ù„Ø¹ØµØ±"
// Bot: "ØªÙ…Ø§Ù…ØŒ ØªÙ… Ø§Ù„Ø­Ø¬Ø² ÙŠÙˆÙ… Ø§Ù„Ø³Ø¨Øª Ø§Ù„Ø³Ø§Ø¹Ø© 3 Ø§Ù„Ø¹ØµØ±"
```

#### **Feature 3: Proactive Suggestions**
```typescript
// Ø§Ù‚ØªØ±Ø§Ø­Ø§Øª Ø§Ø³ØªØ¨Ø§Ù‚ÙŠØ© Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„Ø³ÙŠØ§Ù‚
if (intent === 'inquiry' && confidence < 0.6) {
  // Ø§Ù„Ø³Ø¤Ø§Ù„ ØºÙŠØ± ÙˆØ§Ø¶Ø­
  suggestions = [
    "Ù‡Ù„ ØªÙ‚ØµØ¯: ÙƒÙ… Ø³Ø¹Ø± Ø§Ù„Ù…Ù†ØªØ¬ØŸ",
    "Ù‡Ù„ ØªÙ‚ØµØ¯: Ù…ØªÙ‰ Ù…ÙˆØ¹Ø¯ Ø§Ù„ØªØ³Ù„ÙŠÙ…ØŸ",
    "Ù‡Ù„ ØªÙ‚ØµØ¯: ÙƒÙŠÙ Ø£ØªÙˆØ§ØµÙ„ Ù…Ø¹ Ø§Ù„Ø¯Ø¹Ù…ØŸ"
  ];
}

// Ø¥Ø¶Ø§ÙØ© Ù„Ù„Ø±Ø¯
response += `\n\n**Ù…Ù…ÙƒÙ† ØªÙ‚ØµØ¯:**\n${suggestions.map((s, i) => `${i+1}. ${s}`).join('\n')}`;
```

#### **Feature 4: A/B Testing Ù„Ù„Ù€ Prompts**
```typescript
// Ø§Ø®ØªØ¨Ø§Ø± Prompts Ù…Ø®ØªÙ„ÙØ©
const variants = [
  {
    id: 'v1',
    prompt: 'You are a friendly assistant...',
    traffic: 0.5  // 50% Ù…Ù† Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…ÙŠÙ†
  },
  {
    id: 'v2',
    prompt: 'You are a professional expert...',
    traffic: 0.5  // 50% Ù…Ù† Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…ÙŠÙ†
  }
];

// ØªØªØ¨Ø¹ Ø§Ù„Ù†ØªØ§Ø¦Ø¬
trackMetrics({
  variant: 'v1',
  response_time: 1.2,
  user_rating: 4.5,
  resolution_rate: 0.85
});
```

### 7.4 Security & Privacy ğŸ”’

#### **Enhancement 1: PII Detection**
```typescript
// ÙƒØ´Ù Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ø´Ø®ØµÙŠØ©
const piiPatterns = {
  email: /\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\.[A-Z|a-z]{2,}\b/,
  phone: /\b\d{10,15}\b/,
  creditCard: /\b\d{4}[\s-]?\d{4}[\s-]?\d{4}[\s-]?\d{4}\b/
};

// Ø¥Ø®ÙØ§Ø¡ ÙÙŠ Logs
function sanitize(text: string): string {
  let sanitized = text;
  sanitized = sanitized.replace(piiPatterns.email, '[EMAIL]');
  sanitized = sanitized.replace(piiPatterns.phone, '[PHONE]');
  sanitized = sanitized.replace(piiPatterns.creditCard, '[CARD]');
  return sanitized;
}
```

#### **Enhancement 2: Rate Limiting**
```typescript
// Ù…Ù†Ø¹ Ø§Ù„Ø¥Ø³Ø§Ø¡Ø©
const limits = {
  messages_per_minute: 20,
  messages_per_hour: 200,
  messages_per_day: 1000
};

// ØªØ·Ø¨ÙŠÙ‚
const key = `ratelimit:${visitorId}:${window}`;
const count = await redis.incr(key);
if (count > limit) {
  throw new Error('Rate limit exceeded');
}
```

---

## 8. Ø§Ù„Ù…Ù„Ø®Øµ Ø§Ù„ØªÙ†ÙÙŠØ°ÙŠ ğŸ“Š

### 8.1 Ù†Ù‚Ø§Ø· Ø§Ù„Ù‚ÙˆØ© âœ…

1. **Ù…Ø¹Ù…Ø§Ø±ÙŠØ© Ù‚ÙˆÙŠØ©**
   - ØªØµÙ…ÙŠÙ… Ø·Ø¨Ù‚ÙŠ ÙˆØ§Ø¶Ø­
   - Separation of concerns
   - Easy to test & debug

2. **ØªØ­Ù„ÙŠÙ„ Ø°ÙƒÙŠ**
   - Intent detection (8 Ø£Ù†ÙˆØ§Ø¹)
   - Sentiment analysis (5 Ù…Ø´Ø§Ø¹Ø±)
   - Dialect detection (8 Ù„Ù‡Ø¬Ø§Øª)

3. **RAG System Ù…ØªÙ‚Ø¯Ù…**
   - Vector search with pgvector
   - Reranking for better accuracy
   - Multi-provider fallback

4. **Caching Ø°ÙƒÙŠ**
   - 3 Ù…Ø³ØªÙˆÙŠØ§Øª cache
   - ÙŠÙ‚Ù„Ù„ Ø§Ù„ØªÙƒÙ„ÙØ© 40%
   - ÙŠØ­Ø³Ù† Ø§Ù„Ø³Ø±Ø¹Ø© 60%

### 8.2 Ù†Ù‚Ø§Ø· Ø§Ù„Ø¶Ø¹Ù âŒ

1. **Ù†Ù…ÙˆØ°Ø¬ AI Ø¶Ø¹ÙŠÙ**
   - llama-3.1-8b Ù…Ø­Ø¯ÙˆØ¯
   - Ø±Ø¯ÙˆØ¯ Ù‚ØµÙŠØ±Ø© Ø£Ø­ÙŠØ§Ù†Ø§Ù‹
   - ØµØ¹ÙˆØ¨Ø© ÙÙŠ Ø§Ù„Ø³ÙŠØ§Ù‚ Ø§Ù„Ù…Ø¹Ù‚Ø¯

2. **Vector Search ØºÙŠØ± Ù…Ø³ØªÙ‚Ø±**
   - ÙŠÙØ´Ù„ Ø£Ø­ÙŠØ§Ù†Ø§Ù‹
   - pgvector Ù‚Ø¯ ÙŠÙƒÙˆÙ† ØºÙŠØ± Ù…ÙØ¹Ù‘Ù„
   - Fallback Ø¶Ø¹ÙŠÙ

3. **Dialect Detection Ø¯Ù‚Ø© Ù…ØªÙˆØ³Ø·Ø©**
   - 60-65% accuracy ÙÙ‚Ø·
   - ÙŠØ­ØªØ§Ø¬ ML model
   - Keywords Ù…Ø­Ø¯ÙˆØ¯Ø©

### 8.3 Ø§Ù„Ø£ÙˆÙ„ÙˆÙŠØ§Øª ğŸ¯

**Priority 1 (Critical):**
1. ØªØ±Ù‚ÙŠØ© Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ù„Ù€ 70B Ø£Ùˆ GPT-4
2. Ø¥ØµÙ„Ø§Ø­ Vector Search
3. Ø¥Ø¶Ø§ÙØ© Streaming responses

**Priority 2 (High):**
1. ØªØ­Ø³ÙŠÙ† Dialect Detection (ML)
2. Context Memory
3. Multi-turn Conversations

**Priority 3 (Medium):**
1. A/B Testing
2. Proactive Suggestions
3. PII Detection

---

## 9. Ø§Ù„Ø®Ø§ØªÙ…Ø© ğŸ“

Ù‡Ø°Ø§ Ø§Ù„Ù†Ø¸Ø§Ù… Ù‡Ùˆ **Ø£Ø³Ø§Ø³ Ø§Ù„Ù…Ø´Ø±ÙˆØ¹** ÙˆÙŠØ¹Ù…Ù„ Ø¨Ø´ÙƒÙ„ Ø¬ÙŠØ¯ Ø­Ø§Ù„ÙŠØ§Ù‹ØŒ Ù„ÙƒÙ† ÙŠØ­ØªØ§Ø¬:

1. **ØªØ±Ù‚ÙŠØ© Ø§Ù„Ù†Ù…ÙˆØ°Ø¬** Ù„Ø±Ø¯ÙˆØ¯ Ø£ÙØ¶Ù„
2. **ØªØ­Ø³ÙŠÙ† Dialect Detection** Ù„Ø¯Ù‚Ø© Ø£Ø¹Ù„Ù‰
3. **Ø¥ØµÙ„Ø§Ø­ Vector Search** Ù„Ø§Ø³ØªÙ‚Ø±Ø§Ø± ÙƒØ§Ù…Ù„

**Ø§Ù„ÙƒÙˆØ¯ Ø¬Ø§Ù‡Ø² Ù„Ù„Ø¥Ù†ØªØ§Ø¬** Ù…Ø¹ Ù‡Ø°Ù‡ Ø§Ù„ØªØ­Ø³ÙŠÙ†Ø§Øª! ğŸš€

---

**ØªØ§Ø±ÙŠØ® Ø§Ù„ØªÙ‚Ø±ÙŠØ±:** 2026-01-03  
**Ø§Ù„Ø¥ØµØ¯Ø§Ø±:** 1.0  
**Ø§Ù„Ø­Ø§Ù„Ø©:** Production Ready (Ù…Ø¹ Ø§Ù„ØªØ­Ø³ÙŠÙ†Ø§Øª Ø§Ù„Ù…Ø°ÙƒÙˆØ±Ø©)
