const axios = require('axios');
const logger = require('../utils/logger');
const intentDetection = require('./intent-detection.service');
const conversationState = require('./conversation-state.service');
const kbPreparation = require('./kb-preparation.service');

/**
 * Hybrid AI Service - Intelligent Load Balancing Across Free Tier Providers
 * 
 * FREE TIER LIMITS:
 * - Groq: 30 req/min, 14,400 tokens/min
 * - Gemini: 15 req/min, 1M tokens/day
 * - Cerebras: 30 req/min
 * - DeepSeek: 60 req/min (most generous)
 * 
 * Strategy: Round-robin load balancing with smart fallback
 */

// Provider Definitions (API keys resolved at runtime for better testability)
const PROVIDER_DEFINITIONS = {
  GROQ: {
    name: 'Groq',
    endpoint: 'https://api.groq.com/openai/v1/chat/completions',
    envVar: 'GROQ_API_KEY',
    model: 'groq/compound',
    rateLimit: { requestsPerMinute: 30, tokensPerMinute: 14400 },
    priority: 1, // PRIMARY - Fast and reliable
    enabled: true
  },
  CEREBRAS: {
    name: 'Cerebras',
    endpoint: 'https://api.cerebras.ai/v1/chat/completions',
    envVar: 'CEREBRAS_API_KEY',
    model: 'llama3.1-8b',
    rateLimit: { requestsPerMinute: 30, tokensPerMinute: 30000 },
    priority: 3,
    enabled: true
  },
  GEMINI: {
    name: 'Gemini',
    endpoint: 'https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash-latest:generateContent',
    envVar: 'GEMINI_API_KEY',
    model: 'gemini-1.5-flash',
    rateLimit: { requestsPerMinute: 15, tokensPerDay: 1000000 },
    priority: 4,
    enabled: true,
    isGemini: true
  },
  DEEPSEEK: {
    name: 'DeepSeek',
    endpoint: 'https://api.deepseek.com/v1/chat/completions',
    envVar: 'DEEPSEEK_API_KEY',
    model: 'deepseek-chat',
    rateLimit: { requestsPerMinute: 60, tokensPerMinute: 50000 },
    priority: 2, // SECONDARY - Balance restored, fast and reliable
    enabled: true // Re-enabled after balance added
  }
  ,
  VOYAGE: {
    name: 'VoyageAI',
    endpoint: process.env.VOYAGE_CHAT_URL || 'https://api.voyageai.com/v1/chat/completions',
    envVar: 'VOYAGE_API_KEY',
    model: process.env.VOYAGE_MODEL || 'voyage-chat',
    rateLimit: { requestsPerMinute: 50, tokensPerMinute: 50000 },
    priority: 2,
    enabled: true
  }
};

function getProviderConfig(providerKey) {
  const definition = PROVIDER_DEFINITIONS[providerKey];
  if (!definition) return null;

  const apiKey = process.env[definition.envVar];
  const baseEnabled = definition.enabled !== false;

  return {
    ...definition,
    apiKey,
    enabled: baseEnabled && !!apiKey,
    configured: !!apiKey
  };
}

function getProviders() {
  return Object.keys(PROVIDER_DEFINITIONS).reduce((acc, key) => {
    acc[key] = getProviderConfig(key);
    return acc;
  }, {});
}

// Utility to reset internal state (primarily used in tests)
function resetProviderState() {
  currentProviderIndex = 0;
  Object.keys(usageTracker).forEach(key => {
    usageTracker[key].requests = [];
    usageTracker[key].tokens = [];
  });
}

// Usage tracking for rate limit management
const usageTracker = {
  DEEPSEEK: { requests: [], tokens: [] },
  VOYAGE: { requests: [], tokens: [] },
  GROQ: { requests: [], tokens: [] },
  CEREBRAS: { requests: [], tokens: [] },
  GEMINI: { requests: [], tokens: [] }
};

// Round-robin index
let currentProviderIndex = 0;

/**
 * Clean up old usage records (older than 1 minute/1 day)
 */
function cleanupUsageTracker(provider, type = 'requests') {
  const now = Date.now();
  const timeWindow = type === 'requests' ? 60 * 1000 : 24 * 60 * 60 * 1000; // 1 min or 1 day
  
  if (!usageTracker[provider]) return;
  usageTracker[provider][type] = usageTracker[provider][type].filter(
    timestamp => (now - timestamp) < timeWindow
  );
}

/**
 * Check if provider is available (not rate limited)
 */
function isProviderAvailable(providerKey, providerConfig = getProviderConfig(providerKey)) {
  const provider = providerConfig;
  if (!provider || !provider.enabled || !provider.apiKey) return false;

  cleanupUsageTracker(providerKey, 'requests');
  cleanupUsageTracker(providerKey, 'tokens');

  const tracker = usageTracker[providerKey];
  const limits = provider.rateLimit;

  // Check request rate limit
  if (tracker.requests.length >= limits.requestsPerMinute) {
    logger.warn(`${provider.name} rate limit reached`, {
      current: tracker.requests.length,
      limit: limits.requestsPerMinute
    });
    return false;
  }

  // Check token rate limit (if applicable)
  if (limits.tokensPerMinute) {
    const tokenCount = tracker.tokens.reduce((sum, t) => sum + t.count, 0);
    if (tokenCount >= limits.tokensPerMinute) {
      logger.warn(`[HybridAI] ${provider.name} token limit reached`, { tokenCount, limit: limits.tokensPerMinute });
      return false;
    }
  }

  return true;
}

/**
 * Record usage for rate limit tracking
 */
function recordUsage(providerKey, tokensUsed = 0) {
  const now = Date.now();
  usageTracker[providerKey].requests.push(now);
  if (tokensUsed > 0) {
    usageTracker[providerKey].tokens.push({ timestamp: now, count: tokensUsed });
  }
}

/**
 * Get next available provider using round-robin with smart fallback
 */
function getNextProvider() {
  const providerKeys = Object.keys(PROVIDER_DEFINITIONS).sort((a, b) => 
    PROVIDER_DEFINITIONS[a].priority - PROVIDER_DEFINITIONS[b].priority
  );

  // Try round-robin first
  let attempts = 0;
  while (attempts < providerKeys.length) {
    const provider = providerKeys[currentProviderIndex % providerKeys.length];
    currentProviderIndex++;

    const config = getProviderConfig(provider);
    if (isProviderAvailable(provider, config)) {
      return { key: provider, config };
    }
    attempts++;
  }

  // If all providers are rate limited, wait and retry with highest priority
  logger.warn('[HybridAI] All providers rate limited. Using fallback strategy...');
  return null;
}

/**
 * Convert OpenAI format to Gemini format
 */
function convertToGeminiFormat(messages) {
  const contents = [];
  let systemInstruction = '';

  messages.forEach(msg => {
    if (msg.role === 'system') {
      systemInstruction = msg.content;
    } else {
      contents.push({
        role: msg.role === 'assistant' ? 'model' : 'user',
        parts: [{ text: msg.content }]
      });
    }
  });

  return {
    contents,
    systemInstruction: systemInstruction || undefined,
    generationConfig: {
      temperature: 0.7,
      maxOutputTokens: 1024,
      topP: 0.9
    }
  };
}

/**
 * Convert Gemini response to OpenAI format
 */
function convertGeminiResponse(geminiResponse) {
  const candidate = geminiResponse.candidates?.[0];
  if (!candidate) {
    throw new Error('No response from Gemini');
  }

  return {
    response: candidate.content.parts[0].text,
    tokensUsed: geminiResponse.usageMetadata?.totalTokenCount || 0,
    model: 'gemini-1.5-flash'
  };
}

/**
 * Call AI provider with proper error handling
 */
async function callProvider(providerKey, providerConfig, messages, options = {}) {
  const startTime = Date.now();
  const logger = require('../utils/logger');
  
  try {
    logger.debug('AI provider call initiated', { provider: providerConfig.name });

    // Special handling for Gemini
    if (providerConfig.isGemini) {
      const geminiPayload = convertToGeminiFormat(messages);
      const response = await axios.post(
        `${providerConfig.endpoint}?key=${providerConfig.apiKey}`,
        geminiPayload,
        {
          headers: { 'Content-Type': 'application/json' },
          timeout: 30000
        }
      );

      const result = convertGeminiResponse(response.data);
      recordUsage(providerKey, result.tokensUsed);
      
      logger.info('AI provider success', { provider: providerConfig.name, duration: Date.now() - startTime, tokens: result.tokensUsed });
      return result;
    }

    // Standard OpenAI-compatible format
    const payload = {
      model: providerConfig.model,
      messages,
      temperature: options.temperature || 0.7,
      max_tokens: options.maxTokens || 1024,
      top_p: options.topP || 0.9
    };

    const response = await axios.post(
      providerConfig.endpoint,
      payload,
      {
        headers: {
          'Authorization': `Bearer ${providerConfig.apiKey}`,
          'Content-Type': 'application/json'
        },
        timeout: 30000
      }
    );

    if (!response.data?.choices?.[0]?.message?.content) {
      throw new Error('Invalid response format');
    }

    const result = {
      response: response.data.choices[0].message.content,
      tokensUsed: response.data.usage?.total_tokens || 0,
      model: providerConfig.model,
      provider: providerConfig.name
    };

    recordUsage(providerKey, result.tokensUsed);
    
    logger.info('AI provider success', { provider: providerConfig.name, duration: Date.now() - startTime, tokensUsed: result.tokensUsed });
    return result;

  } catch (error) {
    const duration = Date.now() - startTime;
    logger.error('AI provider failed', { 
      provider: providerConfig.name, 
      duration, 
      error: error.message,
      statusCode: error.response?.status
    });
    
    // Classify error type
    if (error.response?.status === 429) {
      throw new Error('RATE_LIMIT');
    } else if (error.response?.status === 401 || error.response?.status === 403) {
      throw new Error('AUTH_ERROR');
    } else if (error.code === 'ECONNABORTED' || error.code === 'ETIMEDOUT') {
      throw new Error('TIMEOUT');
    }
    
    throw error;
  }
}

/**
 * Generate AI response with intelligent provider selection and fallback
 * @param {Array} messages - Array of {role, content} messages
 * @param {Object} options - Additional options (temperature, maxTokens, etc.)
 * @returns {Promise<Object>} - { response, tokensUsed, model, provider }
 */
async function generateResponse(messages, options = {}) {
  let lastError = null;
  let attemptCount = 0;
  const maxAttempts = Object.keys(PROVIDER_DEFINITIONS).length;

  while (attemptCount < maxAttempts) {
    attemptCount++;

    // Get next available provider
    const provider = getNextProvider();
    
    if (!provider) {
      // All providers exhausted, wait a bit and retry
      logger.warn('[HybridAI] All providers unavailable. Waiting 2 seconds...');
      await new Promise(resolve => setTimeout(resolve, 2000));
      continue;
    }

    try {
      const result = await callProvider(provider.key, provider.config, messages, options);
      
      // Success! Return result
      logger.info('AI request completed successfully', { provider: provider.config.name, attempt: attemptCount, model: result.model });
      return result;

    } catch (error) {
      lastError = error;
      logger.warn('AI attempt failed, retrying', { attempt: attemptCount, maxAttempts, provider: provider.config.name, error: error.message });
      
      // If rate limit error, mark provider as temporarily unavailable
      if (error.message === 'RATE_LIMIT') {
        // Add fake timestamps to prevent immediate retry
        for (let i = 0; i < provider.config.rateLimit.requestsPerMinute; i++) {
          usageTracker[provider.key].requests.push(Date.now());
        }
      }
      
      // Continue to next provider
      continue;
    }
  }

  // All providers failed
  logger.error('[HybridAI] ğŸ’¥ All providers exhausted. Last error:', lastError?.message);
  throw new Error(`All AI providers failed. Last error: ${lastError?.message || 'Unknown error'}`);
}

/**
 * Get provider status and statistics
 */
function getProviderStatus() {
  const status = {};
  
  Object.keys(PROVIDER_DEFINITIONS).forEach(key => {
    const provider = getProviderConfig(key);
    const tracker = usageTracker[key];
    
    cleanupUsageTracker(key, 'requests');
    cleanupUsageTracker(key, 'tokens');
    
    const tokenCount = tracker.tokens.reduce((sum, t) => sum + t.count, 0);
    
    status[key] = {
      name: provider.name,
      enabled: provider.enabled && !!provider.apiKey,
      available: isProviderAvailable(key, provider),
      currentUsage: {
        requests: tracker.requests.length,
        tokens: tokenCount
      },
      limits: provider.rateLimit,
      utilization: {
        requests: `${tracker.requests.length}/${provider.rateLimit.requestsPerMinute}`,
        requestsPercent: Math.round((tracker.requests.length / provider.rateLimit.requestsPerMinute) * 100),
        tokens: provider.rateLimit.tokensPerMinute 
          ? `${tokenCount}/${provider.rateLimit.tokensPerMinute}`
          : 'N/A'
      }
    };
  });
  
  return status;
}

/**
 * Health check - test all providers
 */
async function healthCheck() {
  const results = {};
  const testMessages = [
    { role: 'system', content: 'You are a helpful assistant.' },
    { role: 'user', content: 'Say "OK" if you can read this.' }
  ];

  for (const key of Object.keys(PROVIDER_DEFINITIONS)) {
    const provider = getProviderConfig(key);
    if (!provider.enabled || !provider.apiKey) {
      results[key] = { status: 'disabled', reason: 'No API key or disabled' };
      continue;
    }

    try {
      const result = await callProvider(key, provider, testMessages, { maxTokens: 10 });
      results[key] = { 
        status: 'healthy', 
        responseTime: 'fast',
        response: result.response.substring(0, 50)
      };
    } catch (error) {
      results[key] = { 
        status: 'error', 
        reason: error.message 
      };
    }
  }

  return results;
}

/**
 * Get provider stats for monitoring
 */
function getProviderStats() {
  return getProviderStatus();
}

/**
 * Check providers health summary
 */
function checkProvidersHealth() {
  const status = getProviderStatus();
  const providers = Object.values(status);
  
  const totalConfigured = providers.filter(p => p.enabled).length;
  const totalAvailable = providers.filter(p => p.available).length;
  
  return {
    totalConfigured,
    totalAvailable,
    providers: providers.map(p => ({
      name: p.name,
      status: p.available ? 'available' : (p.enabled ? 'rate-limited' : 'disabled')
    }))
  };
}

/**
 * Generate a response using a specific provider (no fallback)
 * Useful for diagnostics and admin testing.
 */
async function generateResponseWithProvider(providerKey, messages, options = {}) {
  const key = providerKey?.toUpperCase();
  const provider = key ? getProviderConfig(key) : null;

  if (!provider) {
    throw new Error(`Provider ${providerKey} is not supported`);
  }

  if (!provider.enabled || !provider.apiKey) {
    throw new Error(`${provider.name} is not configured or disabled`);
  }

  return callProvider(key, provider, messages, options);
}

/**
 * Generate greeting message based on business and state
 */
function generateGreeting(business, state) {
  const businessName = business.name || 'Ø§Ù„Ø¹Ù…ÙŠÙ„';
  const personality = business.widgetConfig?.personality || business.botTone || 'friendly';
  const welcomeMessage = business.widgetConfig?.welcomeMessage;
  
  if (welcomeMessage) {
    return welcomeMessage;
  }
  
  if (personality === 'formal') {
    return `Ù…Ø±Ø­Ø¨Ø§Ù‹ Ø¨Ùƒ ÙÙŠ ${businessName}. ÙƒÙŠÙ ÙŠÙ…ÙƒÙ†Ù†ÙŠ Ù…Ø³Ø§Ø¹Ø¯ØªÙƒ Ø§Ù„ÙŠÙˆÙ…ØŸ`;
  } else if (personality === 'fun') {
    return `Ù…Ø±Ø­Ø¨Ø§Ù‹! ğŸ‰ Ø£Ù‡Ù„Ø§Ù‹ ÙˆØ³Ù‡Ù„Ø§Ù‹ Ø¨Ùƒ ÙÙŠ ${businessName}. ÙƒÙŠÙ ÙŠÙ…ÙƒÙ†Ù†ÙŠ Ù…Ø³Ø§Ø¹Ø¯ØªÙƒØŸ`;
  } else {
    return `Ù…Ø±Ø­Ø¨Ø§Ù‹! Ø£Ù‡Ù„Ø§Ù‹ ÙˆØ³Ù‡Ù„Ø§Ù‹ Ø¨Ùƒ ÙÙŠ ${businessName}. ÙƒÙŠÙ ÙŠÙ…ÙƒÙ†Ù†ÙŠ Ù…Ø³Ø§Ø¹Ø¯ØªÙƒ Ø§Ù„ÙŠÙˆÙ…ØŸ`;
  }
}

/**
 * Generate a chat response with full context management (System Prompt, History, Knowledge)
 * @param {string} message - User message
 * @param {Object} business - Business context (name, tone, etc.)
 * @param {Array} history - Conversation history
 * @param {Array} knowledgeBase - Relevant knowledge chunks
 * @param {string} conversationId - Optional conversation ID for state tracking
 */
async function generateChatResponse(message, business, history = [], knowledgeBase = [], conversationId = null) {
  // 1. Detect intent and get conversation state
  const intent = intentDetection.detectIntent(message, history);
  const state = conversationId 
    ? await conversationState.getState(conversationId)
    : conversationState.createInitialState();
  
  const updatedState = conversationState.updateState(state, intent);
  
  // 2. Handle special intents before KB search
  if (intent.intent === 'GREETING' && updatedState.isFirstMessage) {
    const greeting = generateGreeting(business, updatedState);
    return {
      response: greeting,
      tokensUsed: 0,
      model: 'greeting',
      intent: intent.intent,
      knowledgeBaseUsed: false
    };
  }
  
  if (intent.intent === 'PROFANITY') {
    return {
      response: `Ø£ÙÙ‡Ù… Ø£Ù†Ùƒ Ù…Ø­Ø¨Ø·. Ø¯Ø¹Ù†ÙŠ Ø£ÙˆØµÙ„Ùƒ Ø¨ÙØ±ÙŠÙ‚Ù†Ø§ Ù„Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ù…Ø³Ø§Ø¹Ø¯Ø© Ø£ÙØ¶Ù„.`,
      tokensUsed: 0,
      model: 'deflection',
      intent: intent.intent,
      knowledgeBaseUsed: false
    };
  }
  
  if (intent.intent === 'OFF_TOPIC') {
    return {
      response: `Ø£Ù†Ø§ Ù‡Ù†Ø§ Ù„Ù…Ø³Ø§Ø¹Ø¯ØªÙƒ Ø¨Ø®ØµÙˆØµ ${business.name || 'Ø®Ø¯Ù…Ø§ØªÙ†Ø§'}. ÙƒÙŠÙ ÙŠÙ…ÙƒÙ†Ù†ÙŠ Ù…Ø³Ø§Ø¹Ø¯ØªÙƒØŸ`,
      tokensUsed: 0,
      model: 'redirect',
      intent: intent.intent,
      knowledgeBaseUsed: false
    };
  }
  
  // 3. Prepare knowledge base chunks (summarize, limit to 3)
  const preparedKB = kbPreparation.prepareKnowledgeChunks(knowledgeBase, 3);
  const hasKnowledgeBase = preparedKB.length > 0;
  
  // 4. Construct System Prompt (SIMPLIFIED - no contradictions)
  const businessName = business.name || 'Ø§Ù„Ø¹Ù…ÙŠÙ„';
  const personality = business.widgetConfig?.personality || business.botTone || 'friendly';
  
  // Build business-specific context
  let businessContext = '';
  if (business.activityType) {
    const businessTypeDescriptions = {
      'RESTAURANT': 'Ù…Ø·Ø¹Ù…',
      'CAFE': 'Ù…Ù‚Ù‡Ù‰',
      'BAKERY': 'Ù…Ø®Ø¨Ø²',
      'CLINIC': 'Ø¹ÙŠØ§Ø¯Ø© Ø·Ø¨ÙŠØ©',
      'HOSPITAL': 'Ù…Ø³ØªØ´ÙÙ‰',
      'PHARMACY': 'ØµÙŠØ¯Ù„ÙŠØ©',
      'DENTAL': 'Ø¹ÙŠØ§Ø¯Ø© Ø£Ø³Ù†Ø§Ù†',
      'RETAIL': 'Ù…ØªØ¬Ø±',
      'FASHION': 'Ù…ØªØ¬Ø± Ø£Ø²ÙŠØ§Ø¡',
      'ELECTRONICS': 'Ù…ØªØ¬Ø± Ø¥Ù„ÙƒØªØ±ÙˆÙ†ÙŠØ§Øª',
      'JEWELRY': 'Ù…ØªØ¬Ø± Ù…Ø¬ÙˆÙ‡Ø±Ø§Øª',
      'FURNITURE': 'Ù…ØªØ¬Ø± Ø£Ø«Ø§Ø«',
      'COMPANY': 'Ø´Ø±ÙƒØ©',
      'CONSULTING': 'Ø´Ø±ÙƒØ© Ø§Ø³ØªØ´Ø§Ø±Ø§Øª',
      'LEGAL': 'Ù…ÙƒØªØ¨ Ù…Ø­Ø§Ù…Ø§Ø©',
      'ACCOUNTING': 'Ù…ÙƒØªØ¨ Ù…Ø­Ø§Ø³Ø¨Ø©',
      'REALESTATE': 'Ù…ÙƒØªØ¨ Ø¹Ù‚Ø§Ø±Ø§Øª',
      'IT': 'Ø´Ø±ÙƒØ© ØªÙ‚Ù†ÙŠØ©',
      'SOFTWARE': 'Ø´Ø±ÙƒØ© Ø¨Ø±Ù…Ø¬ÙŠØ§Øª',
      'DIGITAL': 'ÙˆÙƒØ§Ù„Ø© Ø±Ù‚Ù…ÙŠØ©',
      'MARKETING': 'ÙˆÙƒØ§Ù„Ø© ØªØ³ÙˆÙŠÙ‚',
      'DESIGN': 'Ø§Ø³ØªÙˆØ¯ÙŠÙˆ ØªØµÙ…ÙŠÙ…',
      'PHOTOGRAPHY': 'Ø§Ø³ØªÙˆØ¯ÙŠÙˆ ØªØµÙˆÙŠØ±',
      'EVENTS': 'Ø´Ø±ÙƒØ© ÙØ¹Ø§Ù„ÙŠØ§Øª',
      'ECOMMERCE': 'Ù…ØªØ¬Ø± Ø¥Ù„ÙƒØªØ±ÙˆÙ†ÙŠ',
      'DROPSHIPPING': 'Ù…ØªØ¬Ø± Ø¯Ø±ÙˆØ¨ Ø´ÙŠØ¨ÙŠÙ†Ø¬',
      'MAINTENANCE': 'Ø´Ø±ÙƒØ© ØµÙŠØ§Ù†Ø©',
      'SECURITY': 'Ø´Ø±ÙƒØ© Ø£Ù…Ù†',
      'TELECOM': 'Ø´Ø±ÙƒØ© Ø§ØªØµØ§Ù„Ø§Øª',
      'ARCHITECTURE': 'Ù…ÙƒØªØ¨ Ù‡Ù†Ø¯Ø³Ø© Ù…Ø¹Ù…Ø§Ø±ÙŠØ©',
      'INTERIOR': 'Ø´Ø±ÙƒØ© Ø¯ÙŠÙƒÙˆØ± Ø¯Ø§Ø®Ù„ÙŠ',
      'CONSTRUCTION': 'Ø´Ø±ÙƒØ© Ø¨Ù†Ø§Ø¡',
      'EDUCATION': 'Ù…Ø¤Ø³Ø³Ø© ØªØ¹Ù„ÙŠÙ…ÙŠØ©',
      'SCHOOL': 'Ù…Ø¯Ø±Ø³Ø©',
      'UNIVERSITY': 'Ø¬Ø§Ù…Ø¹Ø©',
      'BANK': 'Ø¨Ù†Ùƒ',
      'INSURANCE': 'Ø´Ø±ÙƒØ© ØªØ£Ù…ÙŠÙ†',
      'INVESTMENT': 'Ø´Ø±ÙƒØ© Ø§Ø³ØªØ«Ù…Ø§Ø±',
      'HOTEL': 'ÙÙ†Ø¯Ù‚',
      'TRAVEL': 'ÙˆÙƒØ§Ù„Ø© Ø³ÙØ±',
      'TOURISM': 'Ø´Ø±ÙƒØ© Ø³ÙŠØ§Ø­Ø©',
      'SALON': 'ØµØ§Ù„ÙˆÙ† ØªØ¬Ù…ÙŠÙ„',
      'SPA': 'Ø³Ø¨Ø§',
      'GYM': 'Ù†Ø§Ø¯ÙŠ Ø±ÙŠØ§Ø¶ÙŠ',
      'AUTOMOTIVE': 'Ù…Ø¹Ø±Ø¶ Ø³ÙŠØ§Ø±Ø§Øª',
      'CARMAINTENANCE': 'ÙˆØ±Ø´Ø© ØµÙŠØ§Ù†Ø© Ø³ÙŠØ§Ø±Ø§Øª',
      'LOGISTICS': 'Ø´Ø±ÙƒØ© Ø´Ø­Ù†',
      'OTHER': 'Ø´Ø±ÙƒØ©'
    };
    businessContext = businessTypeDescriptions[business.activityType] || 'Ø´Ø±ÙƒØ©';
  }

  // Personality instructions
  let personalityInstructions = '';
  if (personality === 'friendly') {
    personalityInstructions = 'ÙƒÙ† ÙˆØ¯ÙˆØ¯Ø§Ù‹ ÙˆÙ…Ø±Ø­Ø¨Ø§Ù‹ØŒ Ø§Ø³ØªØ®Ø¯Ù… Ù„ØºØ© Ø¨Ø³ÙŠØ·Ø© ÙˆÙˆØ§Ø¶Ø­Ø©.';
  } else if (personality === 'formal') {
    personalityInstructions = 'ÙƒÙ† Ù…Ø­ØªØ±ÙØ§Ù‹ ÙˆØ±Ø³Ù…ÙŠØ§Ù‹ØŒ Ø§Ø³ØªØ®Ø¯Ù… Ù„ØºØ© Ø£Ø¹Ù…Ø§Ù„ Ø±Ø³Ù…ÙŠØ©.';
  } else if (personality === 'fun') {
    personalityInstructions = 'ÙƒÙ† Ù…Ø±Ø­Ø§Ù‹ ÙˆÙ…Ù…ØªØ¹Ø§Ù‹ØŒ Ø§Ø³ØªØ®Ø¯Ù… Ù„ØºØ© Ø®ÙÙŠÙØ© ÙˆÙ…Ø´ÙˆÙ‚Ø©.';
  } else {
    personalityInstructions = 'ÙƒÙ† ÙˆØ¯ÙˆØ¯Ø§Ù‹ ÙˆÙ…Ù‡Ø°Ø¨Ø§Ù‹.';
  }

  // Time context
  const timeContext = business.currentDate 
    ? `\nØ§Ù„ØªØ§Ø±ÙŠØ® ÙˆØ§Ù„ÙˆÙ‚Øª Ø§Ù„Ø­Ø§Ù„ÙŠ: ${business.currentDate}. Ø§Ø³ØªØ®Ø¯Ù… Ù‡Ø°Ø§ Ù„Ù„Ø¥Ø¬Ø§Ø¨Ø© Ø¹Ù„Ù‰ Ø£Ø³Ø¦Ù„Ø© Ø§Ù„ÙˆÙ‚Øª (Ù…Ø«Ù„: "Ø§Ù„Ù…Ø­Ù„ Ù…ÙØªÙˆØ­ Ø§Ù„Ø¢Ù†ØŸ").`
    : '';

  // 5. Build simplified, non-contradictory system prompt
  let knowledgeContext = '';
  if (hasKnowledgeBase) {
    const formattedKB = kbPreparation.formatForPrompt(preparedKB);
    knowledgeContext = `
Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ù…Ù† Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ù…Ø¹Ø±ÙØ©:
${formattedKB}

Ø§Ø³ØªØ®Ø¯Ù… Ù‡Ø°Ù‡ Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ù„Ù„Ø¥Ø¬Ø§Ø¨Ø© Ø¹Ù„Ù‰ Ø³Ø¤Ø§Ù„ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…. Ø¥Ø°Ø§ Ù„Ù… ØªØ¬Ø¯ Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø© ÙÙŠ Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø£Ø¹Ù„Ø§Ù‡ØŒ Ù‚Ù„ Ø¨ØµØ±Ø§Ø­Ø©: "Ø¹Ø°Ø±Ø§Ù‹ØŒ Ù„Ø§ Ø£Ù…Ù„Ùƒ Ù‡Ø°Ù‡ Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø©. Ù‡Ù„ ØªØ±ÙŠØ¯ Ø§Ù„ØªÙˆØ§ØµÙ„ Ù…Ø¹ ÙØ±ÙŠÙ‚ ${businessName} Ù…Ø¨Ø§Ø´Ø±Ø©ØŸ"
`;
  } else {
    knowledgeContext = `
Ù„Ø§ ØªÙˆØ¬Ø¯ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª ÙÙŠ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ù…Ø¹Ø±ÙØ©. ÙƒÙ† ØµØ±ÙŠØ­Ø§Ù‹ Ù…Ø¹ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… ÙˆØ§Ù‚ØªØ±Ø­ Ø§Ù„ØªÙˆØ§ØµÙ„ Ù…Ø¹ ÙØ±ÙŠÙ‚ ${businessName}.
`;
  }

  // 6. Build final system prompt (SIMPLIFIED - 3-4 clear rules only)
  const systemPrompt = `Ø£Ù†Øª Ù…Ø³Ø§Ø¹Ø¯ ${businessName}${businessContext ? ` (${businessContext})` : ''}.

${personalityInstructions}
${timeContext}

${knowledgeContext}

Ù‚ÙˆØ§Ø¹Ø¯:
1. Ø£Ø¬Ø¨ Ø¨Ù†ÙØ³ Ù„ØºØ© Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… (Ø¹Ø±Ø¨ÙŠ Ø£Ùˆ Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠ)
2. ÙƒÙ† Ù…Ø®ØªØµØ±Ø§Ù‹ (2-3 Ø¬Ù…Ù„ ÙƒØ­Ø¯ Ø£Ù‚ØµÙ‰)
3. Ø§Ø³ØªØ®Ø¯Ù… Markdown Ù„Ù„ØªÙ†Ø³ÙŠÙ‚
4. Ø¹Ù†Ø¯ Ø¥Ù†Ù‡Ø§Ø¡ Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø©ØŒ Ø£Ø¶Ù "|RATING_REQUEST|" ÙÙŠ Ø§Ù„Ù†Ù‡Ø§ÙŠØ©
5. Ù„Ø§ ØªØ°ÙƒØ± Ø£Ù†Ùƒ AI - Ø£Ù†Øª ÙÙ‚Ø· Ù…Ø³Ø§Ø¹Ø¯ ${businessName}
`;

  // 2. Construct Messages Array with enhanced context
  const messages = [
    { role: 'system', content: systemPrompt },
    ...history,
    { role: 'user', content: message }
  ];

  // 7. Adjust temperature based on intent and KB availability
  let temperature = 0.7; // Default
  if (hasKnowledgeBase) {
    temperature = 0.5; // More focused when KB exists (not too low to avoid robotic)
  } else if (intent.intent === 'GREETING') {
    temperature = 0.8; // More creative for greetings
  }
  
  // 8. Call Hybrid AI with optimized options
  const options = {
    temperature,
    maxTokens: 400, // Reduced from 500 for more concise responses
    topP: 0.9
  };

  const result = await generateResponse(messages, options);
  
  // 9. Add metadata
  result.knowledgeBaseUsed = hasKnowledgeBase;
  result.knowledgeBaseCount = preparedKB.length;
  result.intent = intent.intent;
  result.intentConfidence = intent.confidence;
  result.conversationStage = updatedState.stage;
  
  // 10. Add rating request if closing
  if (intent.intent === 'CLOSING' && !result.response.includes('|RATING_REQUEST|')) {
    result.response += ' |RATING_REQUEST|';
  }
  
  return result;
}

module.exports = {
  generateChatResponse,
  generateResponse,
  generateResponseWithProvider,
  getProviderStatus,
  getProviderStats,
  checkProvidersHealth,
  healthCheck,
  resetProviderState,
  getProviders,
  getProviderConfig,
  PROVIDER_DEFINITIONS
};
