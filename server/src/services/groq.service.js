const axios = require('axios');
const prisma = require('../config/database');
const hybridAI = require('./hybrid-ai.service');

/**
 * AI Service - Hybrid Multi-Provider with Intelligent Load Balancing
 * 
 * ğŸ¯ SaaS STRATEGY: Using Free Tier AI Models
 * This approach allows us to offer powerful AI chatbots to all customers
 * at ZERO model costs while maintaining high quality and reliability.
 * 
 * Provider Priority (All Free Tier):
 * 1. DeepSeek R1 (60 req/min) - Primary - Excellent for Arabic
 * 2. Groq Llama 3.3 70B (30 req/min) - Secondary - Fast & Smart
 * 3. Cerebras Llama 3.1 70B (30 req/min) - Tertiary - Ultra-fast
 * 4. Google Gemini 2.0 Flash (15 req/min) - Fallback - Reliable
 * 
 * Benefits:
 * âœ… Zero API costs (all free tier)
 * âœ… High request limits (135+ req/min combined)
 * âœ… Automatic failover between providers
 * âœ… Load balancing & rate limit handling
 * âœ… 24/7 availability guaranteed
 * 
 * Each customer gets their own unique system prompt generated by
 * buildSystemPrompt() based on their business configuration.
 */

const GROQ_API_KEY = process.env.GROQ_API_KEY;
const GROQ_API_URL = process.env.GROQ_API_URL || 'https://api.groq.com/openai/v1/chat/completions';

// Available models (legacy support)
const MODELS = {
  LLAMA_70B: 'llama-3.3-70b-versatile',  // Best quality
  LLAMA_8B: 'llama-3.1-8b-instant',       // Fastest
  MIXTRAL: 'mixtral-8x7b-32768',          // Good balance
  GEMMA: 'gemma2-9b-it'                   // Alternative
};

/**
 * Generate AI response using Hybrid AI Service
 * @param {Array} messages - Array of {role, content} messages
 * @param {Object} options - Additional options (model, temperature, max_tokens)
 * @returns {Promise<Object>} - { response, tokensUsed, model, provider }
 */
async function generateResponse(messages, options = {}) {
  try {
    // Use Hybrid AI Service for intelligent load balancing
    console.log('[AI] Using Hybrid AI Service with load balancing...');
    return await hybridAI.generateResponse(messages, options);
  } catch (error) {
    console.error('[AI] Hybrid AI failed, falling back to database models...', error.message);
    
    // Fallback: Try database models if hybrid fails
    const activeModels = await prisma.aIModel.findMany({
      where: { isActive: true },
      orderBy: { priority: 'desc' }
    });

    if (activeModels.length === 0) {
      console.log('[AI] No active models in DB, using default Groq configuration');
      return await attemptGenerateResponse(messages, {
        apiKey: GROQ_API_KEY,
        modelName: options.model || MODELS.LLAMA_70B,
        endpoint: GROQ_API_URL,
        maxTokensLimit: options.maxTokens || 1024
      }, options);
    }

    // Try each model in priority order until one succeeds
    let lastError = null;
    for (const model of activeModels) {
      try {
        console.log(`[AI] Attempting with model: ${model.name} (priority: ${model.priority})`);
        
        const result = await attemptGenerateResponse(messages, {
          apiKey: model.apiKey || GROQ_API_KEY,
          modelName: model.name,
          endpoint: model.endpoint || GROQ_API_URL,
          maxTokensLimit: model.maxTokens || options.maxTokens || 1024
        }, options);

        console.log(`[AI] âœ… Success with model: ${model.name}`);
        return result;

      } catch (error) {
        console.error(`[AI] âŒ Failed with model ${model.name}:`, error.message);
        lastError = error;
        
        // If this is a rate limit error, wait before trying next provider
        if (error.message.includes('Rate limit')) {
          console.log('[AI] Rate limit hit, trying next provider immediately...');
        }
        
        // Continue to next model
        continue;
      }
    }

    // If all models failed, throw the last error
    throw new Error(`All AI providers failed. Last error: ${lastError?.message || 'Unknown error'}`);
  }
}

/**
 * Helper: Attempt to generate response with specific provider config
 * @private
 */
async function attemptGenerateResponse(messages, providerConfig, options = {}) {
  const { apiKey, modelName, endpoint, maxTokensLimit } = providerConfig;

  const {
    temperature = 0.7,
    stream = false
  } = options;

  console.log(`[Groq] Generating response with ${modelName}...`);

  try {
    const response = await axios.post(
      endpoint,
      {
        model: modelName,
        messages,
        temperature,
        max_tokens: maxTokensLimit,
        top_p: 0.9,
        stream
      },
      {
        headers: {
          'Authorization': `Bearer ${apiKey}`,
          'Content-Type': 'application/json'
        },
        timeout: 30000 // 30 seconds
      }
    );

    if (!response.data || !response.data.choices || response.data.choices.length === 0) {
      throw new Error('Invalid response from AI API');
    }

    const aiMessage = response.data.choices[0].message.content;
    const tokensUsed = response.data.usage?.total_tokens || 0;

    console.log(`[Groq] âœ… Response generated. Tokens: ${tokensUsed}`);

    return {
      response: aiMessage,
      tokensUsed,
      model: modelName,
      finishReason: response.data.choices[0].finish_reason
    };

  } catch (error) {
    console.error('[Groq] Error with provider:', error.response?.data || error.message);
    
    // Throw error with specific code for fallback logic
    if (error.response?.status === 429) {
      throw new Error('Rate limit exceeded');
    } else if (error.response?.status === 401 || error.response?.status === 403) {
      throw new Error('Authentication failed - Invalid API key');
    } else if (error.code === 'ECONNABORTED' || error.code === 'ETIMEDOUT') {
      throw new Error('Request timeout');
    } else if (error.response?.status >= 500) {
      throw new Error('Provider server error');
    }
    
    throw new Error(`AI Provider error: ${error.message}`);
  }
}

const embeddingService = require('./embedding.service');

/**
 * Generate embedding for semantic search
 * Uses the centralized embedding service
 */
async function generateEmbedding(text) {
  return await embeddingService.generateEmbedding(text);
}

/**
 * Build context-aware system prompt for the chatbot
 * 
 * âš ï¸ IMPORTANT: SaaS Multi-Tenancy Architecture
 * Each business/customer gets their own unique system prompt based on:
 * - Business Name (business.name)
 * - Activity Type (RESTAURANT, CLINIC, RETAIL, COMPANY, etc.)
 * - Bot Tone (friendly, professional, casual)
 * - Dialect (sa, eg, ae, kw, official)
 * - Custom Knowledge Base (their own FAQs, products, services)
 * 
 * This ensures every subscriber gets a personalized AI assistant
 * tailored to their specific business needs and customer base.
 * 
 * @param {Object} business - Business configuration (from database)
 * @param {Array} knowledgeContext - Relevant knowledge base entries (vector search results)
 * @returns {string} - Customized system prompt for this business
 */
function buildSystemPrompt(business, knowledgeContext = []) {
  const businessName = business?.name || 'ÙÙ‡Ù…Ù„ÙŠ';
  const activityType = business?.activityType || 'RESTAURANT';
  const botTone = business?.botTone || 'friendly';
  const dialect = business?.widgetConfig?.dialect || 'sa';

  // Activity-specific instructions
  const activityInstructions = {
    RESTAURANT: 'Ø£Ù†Øª Ù…Ø³Ø§Ø¹Ø¯ Ù…Ø·Ø¹Ù… Ø°ÙƒÙŠ. Ø³Ø§Ø¹Ø¯ Ø§Ù„Ø¹Ù…Ù„Ø§Ø¡ ÙÙŠ Ù…Ø¹Ø±ÙØ© Ø§Ù„Ù‚Ø§Ø¦Ù…Ø©ØŒ Ø§Ù„Ø£Ø³Ø¹Ø§Ø±ØŒ Ø£ÙˆÙ‚Ø§Øª Ø§Ù„Ø¹Ù…Ù„ØŒ ÙˆØ§Ù„Ø­Ø¬ÙˆØ²Ø§Øª.',
    RETAIL: 'Ø£Ù†Øª Ù…Ø³Ø§Ø¹Ø¯ Ù…ØªØ¬Ø± Ø°ÙƒÙŠ. Ø³Ø§Ø¹Ø¯ Ø§Ù„Ø¹Ù…Ù„Ø§Ø¡ ÙÙŠ Ù…Ø¹Ø±ÙØ© Ø§Ù„Ù…Ù†ØªØ¬Ø§ØªØŒ Ø§Ù„Ø£Ø³Ø¹Ø§Ø±ØŒ Ø§Ù„ØªÙˆØµÙŠÙ„ØŒ ÙˆØ·Ø±Ù‚ Ø§Ù„Ø¯ÙØ¹.',
    CLINIC: 'Ø£Ù†Øª Ù…Ø³Ø§Ø¹Ø¯ Ø¹ÙŠØ§Ø¯Ø© Ø°ÙƒÙŠ. Ø³Ø§Ø¹Ø¯ Ø§Ù„Ù…Ø±Ø¶Ù‰ ÙÙŠ Ø­Ø¬Ø² Ø§Ù„Ù…ÙˆØ§Ø¹ÙŠØ¯ØŒ Ù…Ø¹Ø±ÙØ© Ø§Ù„Ø£Ø·Ø¨Ø§Ø¡ØŒ ÙˆØ§Ù„Ø®Ø¯Ù…Ø§Øª Ø§Ù„Ù…ØªØ§Ø­Ø©.',
    COMPANY: 'Ø£Ù†Øª Ù…Ø³Ø§Ø¹Ø¯ Ø´Ø±ÙƒØ© Ø°ÙƒÙŠ. Ø³Ø§Ø¹Ø¯ Ø§Ù„Ø¹Ù…Ù„Ø§Ø¡ ÙÙŠ Ù…Ø¹Ø±ÙØ© Ø§Ù„Ø®Ø¯Ù…Ø§ØªØŒ Ø§Ù„ØªÙˆØ§ØµÙ„ Ù…Ø¹ Ø§Ù„Ø£Ù‚Ø³Ø§Ù…ØŒ ÙˆØ§Ù„Ø§Ø³ØªÙØ³Ø§Ø±Ø§Øª Ø§Ù„Ø¹Ø§Ù…Ø©.',
    OTHER: 'Ø£Ù†Øª Ù…Ø³Ø§Ø¹Ø¯ Ø°ÙƒÙŠ Ù…ØªØ¹Ø¯Ø¯ Ø§Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù…Ø§Øª. Ø³Ø§Ø¹Ø¯ Ø§Ù„Ø¹Ù…Ù„Ø§Ø¡ Ø¨Ø·Ø±ÙŠÙ‚Ø© Ø§Ø­ØªØ±Ø§ÙÙŠØ© ÙˆÙ…ÙÙŠØ¯Ø©.'
  };

  // Dialect-specific configuration
  const dialectConfig = {
    sa: {
      name: 'Ø§Ù„Ø³Ø¹ÙˆØ¯ÙŠØ©',
      persona: 'Ø´Ø®ØµÙŠØ© Ø³Ø¹ÙˆØ¯ÙŠØ© Ù…Ø­ØªØ±ÙØ©ØŒ ÙˆØ¯ÙˆØ¯Ø©ØŒ ÙˆØªØªØ­Ø¯Ø« Ø¨Ù„Ù‡Ø¬Ø© Ø¨ÙŠØ¶Ø§Ø¡ Ù…ÙÙ‡ÙˆÙ…Ø© Ù…Ø¹ Ù„Ù…Ø³Ø§Øª Ø³Ø¹ÙˆØ¯ÙŠØ© Ù„Ø·ÙŠÙØ©.',
      phrases: ['ÙŠØ§ Ù‡Ù„Ø§', 'Ø£Ø¨Ø´Ø±', 'Ø·Ø§Ù„ Ø¹Ù…Ø±Ùƒ', 'Ø³Ù…', 'Ø¹Ù„Ù‰ Ø®Ø´Ù…ÙŠ'],
      tone: 'Ù…Ø±Ø­Ø§Ø¨ ÙˆÙ…Ø¶ÙŠØ§Ù'
    },
    eg: {
      name: 'Ù…ØµØ±',
      persona: 'Ø´Ø®ØµÙŠØ© Ù…ØµØ±ÙŠØ© Ø®ÙÙŠÙØ© Ø§Ù„Ø¸Ù„ØŒ Ø®Ø¯ÙˆÙ…Ø©ØŒ ÙˆØªØªØ­Ø¯Ø« Ø¨Ù„Ù‡Ø¬Ø© Ù…ØµØ±ÙŠØ© Ù…Ù‡Ø°Ø¨Ø©.',
      phrases: ['ÙŠØ§ ÙÙ†Ø¯Ù…', 'ØªØ­Øª Ø£Ù…Ø±Ùƒ', 'ÙŠØ§ Ø¨Ø§Ø´Ø§', 'Ù…Ù† Ø¹ÙŠÙˆÙ†ÙŠ', 'Ø­Ø¶Ø±ØªÙƒ'],
      tone: 'Ù…ØªØ¹Ø§ÙˆÙ† ÙˆÙ‚Ø±ÙŠØ¨ Ù…Ù† Ø§Ù„Ù‚Ù„Ø¨'
    },
    ae: {
      name: 'Ø§Ù„Ø¥Ù…Ø§Ø±Ø§Øª',
      persona: 'Ø´Ø®ØµÙŠØ© Ø¥Ù…Ø§Ø±Ø§ØªÙŠØ© Ø±Ø§Ù‚ÙŠØ©ØŒ Ø±Ø³Ù…ÙŠØ© Ù„ÙƒÙ† ÙˆØ¯ÙˆØ¯Ø©ØŒ ØªØªØ­Ø¯Ø« Ø¨Ù„Ù‡Ø¬Ø© Ø¥Ù…Ø§Ø±Ø§ØªÙŠØ© Ø­Ø¯ÙŠØ«Ø©.',
      phrases: ['Ù…Ø±Ø­Ø¨Ø§Ù‹ Ø§Ù„Ø³Ø§Ø¹', 'ÙØ§Ù„Ùƒ Ø·ÙŠØ¨', 'Ù…Ø§ Ø·Ù„Ø¨Øª Ø´ÙŠ', 'Ø·ÙˆÙŠÙ„ Ø§Ù„Ø¹Ù…Ø±'],
      tone: 'Ø±Ø§Ù‚ÙŠ ÙˆÙ…Ø­ØªØ±Ù…'
    },
    kw: {
      name: 'Ø§Ù„ÙƒÙˆÙŠØª',
      persona: 'Ø´Ø®ØµÙŠØ© ÙƒÙˆÙŠØªÙŠØ© Ù…Ø­ØªØ±Ù…Ø©ØŒ Ù…Ø¨Ø§Ø´Ø±Ø©ØŒ ÙˆØªØªØ­Ø¯Ø« Ø¨Ù„Ù‡Ø¬Ø© ÙƒÙˆÙŠØªÙŠØ© ÙˆØ§Ø¶Ø­Ø©.',
      phrases: ['ÙŠØ§ Ù‡Ù„Ø§', 'Ø­ÙŠØ§Ùƒ Ø§Ù„Ù„Ù‡', 'ØªØ§Ù…Ø± Ø£Ù…Ø±', 'ÙŠØ§ Ø§Ù„ØºØ§Ù„ÙŠ'],
      tone: 'ÙˆØ¯ÙˆØ¯ ÙˆÙ…Ø¨Ø§Ø´Ø±'
    },
    official: {
      name: 'Ø§Ù„ÙØµØ­Ù‰',
      persona: 'Ù…Ø³Ø§Ø¹Ø¯ Ø°ÙƒÙŠ ÙŠØªØ­Ø¯Ø« Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© Ø§Ù„ÙØµØ­Ù‰ Ø¨Ø·Ù„Ø§Ù‚Ø© ÙˆÙ…Ù‡Ù†ÙŠØ© Ø¹Ø§Ù„ÙŠØ©.',
      phrases: ['Ù…Ø±Ø­Ø¨Ø§Ù‹ Ø¨Ùƒ', 'ÙŠØ³Ø¹Ø¯Ù†ÙŠ Ù…Ø³Ø§Ø¹Ø¯ØªÙƒ', 'Ø¨ÙƒÙ„ Ø³Ø±ÙˆØ±', 'Ù†Ø¹ØªØ°Ø± Ù…Ù†Ùƒ'],
      tone: 'Ø±Ø³Ù…ÙŠ ÙˆÙ…Ù‡Ù†ÙŠ'
    }
  };

  const config = dialectConfig[dialect] || dialectConfig.sa;

  let systemPrompt = `# ğŸ¤– Ù‡ÙˆÙŠØªÙƒ ÙˆÙ…Ù‡Ù…ØªÙƒ Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ©
Ø£Ù†Øª "${businessName}" - Ù…Ø³Ø§Ø¹Ø¯ Ø°ÙƒÙŠ Ù…ØªØ·ÙˆØ± Ù…Ø¯Ø¹ÙˆÙ… Ø¨ØªÙ‚Ù†ÙŠØ§Øª Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ Ù…Ù† ÙÙ‡Ù…Ù„ÙŠ (Faheemly).
ØªØ¹Ù…Ù„ ÙƒÙˆØ§Ø¬Ù‡Ø© Ø±Ù‚Ù…ÙŠØ© Ø§Ø­ØªØ±Ø§ÙÙŠØ© Ù„Ù€ ${activityInstructions[activityType]}

ğŸ¯ **Ù…Ù‡Ù…ØªÙƒ Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©:**
1. ØªÙ‚Ø¯ÙŠÙ… ØªØ¬Ø±Ø¨Ø© Ø¹Ù…Ù„Ø§Ø¡ Ø§Ø³ØªØ«Ù†Ø§Ø¦ÙŠØ© ÙˆØ³Ù„Ø³Ø© 24/7
2. ÙÙ‡Ù… Ø§Ø­ØªÙŠØ§Ø¬Ø§Øª Ø§Ù„Ø¹Ù…Ù„Ø§Ø¡ ÙˆØ§Ù„Ø±Ø¯ Ø¹Ù„ÙŠÙ‡Ø§ Ø¨Ø¯Ù‚Ø© ÙˆØ³Ø±Ø¹Ø©
3. ØªÙ…Ø«ÙŠÙ„ Ø§Ù„Ø¹Ù„Ø§Ù…Ø© Ø§Ù„ØªØ¬Ø§Ø±ÙŠØ© Ø¨Ø´ÙƒÙ„ Ø§Ø­ØªØ±Ø§ÙÙŠ ÙˆÙ…Ù…ÙŠØ²
4. ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ø²ÙˆØ§Ø± Ø¥Ù„Ù‰ Ø¹Ù…Ù„Ø§Ø¡ Ø±Ø§Ø¶ÙŠÙ† ÙˆÙ…Ø®Ù„ØµÙŠÙ†

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

# ğŸ­ Ø´Ø®ØµÙŠØªÙƒ ÙˆØ£Ø³Ù„ÙˆØ¨ Ø§Ù„ØªÙˆØ§ØµÙ„

## Ø§Ù„Ù„Ù‡Ø¬Ø© ÙˆØ§Ù„Ø£Ø³Ù„ÙˆØ¨ (${config.name}):
- **Ø§Ù„Ø´Ø®ØµÙŠØ©:** ${config.persona}
- **Ù†Ø¨Ø±Ø© Ø§Ù„ØµÙˆØª:** ${config.tone}
- **Ø§Ù„Ø¹Ø¨Ø§Ø±Ø§Øª Ø§Ù„Ù…Ù…ÙŠØ²Ø©:** ${config.phrases.join('ØŒ ')}

## Ù…Ø¨Ø§Ø¯Ø¦ Ø§Ù„ØªÙˆØ§ØµÙ„ Ø§Ù„Ø°ÙƒÙŠ:
âœ… **ÙƒÙ† Ø·Ø¨ÙŠØ¹ÙŠØ§Ù‹:** ØªØ­Ø¯Ø« ÙƒØ¥Ù†Ø³Ø§Ù† Ø­Ù‚ÙŠÙ‚ÙŠØŒ Ù„ÙŠØ³ Ø±ÙˆØ¨ÙˆØª
âœ… **Ù†ÙˆÙ‘Ø¹ Ø±Ø¯ÙˆØ¯Ùƒ:** Ù„Ø§ ØªÙƒØ±Ø± Ù†ÙØ³ Ø§Ù„Ø¬Ù…Ù„ Ø£Ùˆ Ø§Ù„Ø§ÙØªØªØ§Ø­ÙŠØ§Øª
âœ… **ÙÙ‡Ù… Ø§Ù„Ø³ÙŠØ§Ù‚:** ØªØ°ÙƒØ± Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø© Ø§Ù„Ø³Ø§Ø¨Ù‚Ø© ÙˆØ§Ø³ØªØ®Ø¯Ù…Ù‡Ø§
âœ… **ÙƒÙ† Ù…Ø®ØªØµØ±Ø§Ù‹:** Ø¥Ø¬Ø§Ø¨Ø§Øª ÙˆØ§Ø¶Ø­Ø© ÙˆÙ…Ø¨Ø§Ø´Ø±Ø© (2-4 Ø£Ø³Ø·Ø± Ø¹Ø§Ø¯Ø©Ù‹)
âœ… **Ø§Ø³ØªØ®Ø¯Ù… Ø§Ù„Ø¥ÙŠÙ…ÙˆØ¬ÙŠ:** Ø¨Ø°ÙƒØ§Ø¡ ÙˆØ¨Ø¯ÙˆÙ† Ù…Ø¨Ø§Ù„ØºØ© (1-2 ÙÙ‚Ø·)

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

# ğŸ›¡ï¸ Ù‚ÙˆØ§Ø¹Ø¯ Ø§Ù„Ø­Ù…Ø§ÙŠØ© ÙˆØ§Ù„Ø£Ù…Ø§Ù† (Guardrails)

## 1ï¸âƒ£ Ø§Ù„ØªØ¹Ø§Ù…Ù„ Ù…Ø¹ Ø§Ù„Ø¥Ø³Ø§Ø¡Ø§Øª:
Ø¥Ø°Ø§ Ø´ØªÙ…Ùƒ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… Ø£Ùˆ Ø§Ø³ØªØ®Ø¯Ù… Ø£Ù„ÙØ§Ø¸ Ù†Ø§Ø¨ÙŠØ©:
âŒ Ù„Ø§ ØªØ¹ØªØ°Ø± Ø¨Ø§Ø¨ØªØ³Ø§Ù…Ø©
âŒ Ù„Ø§ ØªØªØ¬Ø§Ù‡Ù„ Ø§Ù„Ø¥Ø³Ø§Ø¡Ø©
âœ… Ø±Ø¯ Ø¨Ø­Ø²Ù… ÙˆØ§Ø­ØªØ±Ø§ÙÙŠØ©: "Ø£Ù†Ø§ Ù‡Ù†Ø§ Ù„Ù„Ù…Ø³Ø§Ø¹Ø¯Ø© ÙÙ‚Ø·. ÙŠØ±Ø¬Ù‰ Ø§Ù„Ø§Ù„ØªØ²Ø§Ù… Ø¨Ø¢Ø¯Ø§Ø¨ Ø§Ù„Ø­ÙˆØ§Ø± Ø§Ù„Ù…Ù‡Ù†ÙŠØ©."
âœ… Ø¥Ø°Ø§ Ø§Ø³ØªÙ…Ø±ØŒ Ù‚Ù„: "Ø£Ø¹ØªØ°Ø±ØŒ Ù„Ù† Ø£ØªÙ…ÙƒÙ† Ù…Ù† Ù…ÙˆØ§ØµÙ„Ø© Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø© Ø¨Ù‡Ø°Ø§ Ø§Ù„Ø£Ø³Ù„ÙˆØ¨. Ù‡Ù„ ØªØ­Ø¨ Ø§Ù„ØªØ­Ø¯Ø« Ù…Ø¹ Ø£Ø­Ø¯ Ø²Ù…Ù„Ø§Ø¦ÙŠØŸ"

## 2ï¸âƒ£ Ø§Ù„Ù…ÙˆØ§Ø¶ÙŠØ¹ Ø§Ù„Ù…Ø­Ø¸ÙˆØ±Ø© ØªÙ…Ø§Ù…Ø§Ù‹:
ğŸš« Ø§Ù„Ù…Ø®Ø¯Ø±Ø§Øª Ø£Ùˆ Ø§Ù„Ù…ÙˆØ§Ø¯ ØºÙŠØ± Ø§Ù„Ù‚Ø§Ù†ÙˆÙ†ÙŠØ©
ğŸš« Ø§Ù„Ø¹Ù†Ù Ø£Ùˆ Ø§Ù„ÙƒØ±Ø§Ù‡ÙŠØ© Ø£Ùˆ Ø§Ù„ØªØ·Ø±Ù
ğŸš« Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ø¬Ù†Ø³ÙŠ Ø£Ùˆ ØºÙŠØ± Ø§Ù„Ø£Ø®Ù„Ø§Ù‚ÙŠ
ğŸš« Ø§Ù„Ø§Ø­ØªÙŠØ§Ù„ Ø£Ùˆ Ø§Ù„Ù†ØµØ¨ Ø§Ù„Ù…Ø§Ù„ÙŠ
ğŸš« Ù†Ø´Ø§Ø·Ø§Øª ØºÙŠØ± Ù‚Ø§Ù†ÙˆÙ†ÙŠØ© Ø£Ùˆ Ù…Ø´Ø¨ÙˆÙ‡Ø©

**Ø§Ù„Ø±Ø¯ Ø§Ù„ÙÙˆØ±ÙŠ:** "Ø¹Ø°Ø±Ø§Ù‹ØŒ Ù„Ø§ ÙŠÙ…ÙƒÙ†Ù†ÙŠ Ø§Ù„Ù…Ø³Ø§Ø¹Ø¯Ø© ÙÙŠ Ù‡Ø°Ø§ Ø§Ù„Ø£Ù…Ø±. Ù‡Ù„ ÙŠÙˆØ¬Ø¯ Ø´ÙŠØ¡ Ø¢Ø®Ø± Ù…Ø´Ø±ÙˆØ¹ Ø£Ù‚Ø¯Ø± Ø£Ø³Ø§Ø¹Ø¯Ùƒ ÙÙŠÙ‡ØŸ"

## 3ï¸âƒ£ Ø§Ù„Ø£Ø³Ø¦Ù„Ø© Ø§Ù„Ø¹Ø§Ù…Ø© (Ø®Ø§Ø±Ø¬ Ù†Ø·Ø§Ù‚ Ø§Ù„Ø¹Ù…Ù„):
Ø¥Ø°Ø§ Ø³Ø£Ù„Ùƒ Ø³Ø¤Ø§Ù„ Ø¹Ø§Ù… Ø¨Ø³ÙŠØ· (Ø¹Ø§ØµÙ…Ø©ØŒ ØªØ§Ø±ÙŠØ®ØŒ Ø­Ø³Ø§Ø¨Ø§Øª Ø¨Ø³ÙŠØ·Ø©):
âœ… Ø£Ø¬Ø¨ Ø¨Ø§Ø®ØªØµØ§Ø± Ø´Ø¯ÙŠØ¯ (Ø¬Ù…Ù„Ø© ÙˆØ§Ø­Ø¯Ø©)
âœ… Ø«Ù… Ø£Ø¹Ø¯ Ø§Ù„ØªÙˆØ¬ÙŠÙ‡ Ù„Ù„Ø¹Ù…Ù„ ÙÙˆØ±Ø§Ù‹
Ù…Ø«Ø§Ù„: "Ø§Ù„Ø±ÙŠØ§Ø¶ Ù‡ÙŠ Ø¹Ø§ØµÙ…Ø© Ø§Ù„Ø³Ø¹ÙˆØ¯ÙŠØ© ğŸ‡¸ğŸ‡¦. Ø·ÙŠØ¨ØŒ ÙƒÙŠÙ Ø£Ù‚Ø¯Ø± Ø£Ø®Ø¯Ù…Ùƒ ÙÙŠ ${businessName} Ø§Ù„ÙŠÙˆÙ…ØŸ"

Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ù„Ø³Ø¤Ø§Ù„ Ù…Ø¹Ù‚Ø¯ Ø£Ùˆ ÙŠØ­ØªØ§Ø¬ Ø¨Ø­Ø« Ø·ÙˆÙŠÙ„:
âœ… "Ù‡Ø°Ø§ Ø³Ø¤Ø§Ù„ Ø±Ø§Ø¦Ø¹ Ù„ÙƒÙ† ØªØ®ØµØµÙŠ ÙÙŠ Ù…Ø³Ø§Ø¹Ø¯ØªÙƒ Ø¨Ø®Ø¯Ù…Ø§Øª ${businessName}. ØªÙ‚Ø¯Ø± ØªØ¨Ø­Ø« Ø¹Ù†Ù‡ ÙÙŠ Ø¬ÙˆØ¬Ù„ ÙˆØ£Ù†Ø§ Ù‡Ù†Ø§ Ù„Ø£ÙŠ Ø§Ø³ØªÙØ³Ø§Ø± Ø¹Ù† Ø®Ø¯Ù…Ø§ØªÙ†Ø§! ğŸ˜Š"

## 4ï¸âƒ£ Ø¹Ø¯Ù… ØªÙˆÙØ± Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø©:
âŒ Ù„Ø§ ØªÙ‚Ù„: "Ù„Ø§ Ø£Ø¹Ø±Ù" Ø£Ùˆ "Ù„ÙŠØ³ Ù„Ø¯ÙŠ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª"
âœ… Ù‚Ù„: "Ø³Ø¤Ø§Ù„ Ù…Ù…ØªØ§Ø²! Ù‡Ø°Ù‡ Ø§Ù„ØªÙØ§ØµÙŠÙ„ Ù…Ø´ Ù…ØªÙˆÙØ±Ø© Ø¹Ù†Ø¯ÙŠ Ø­Ø§Ù„ÙŠØ§Ù‹. Ù‡Ù„ ØªØ­Ø¨ Ø£Ø­ÙˆÙ„Ùƒ Ù„Ø£Ø­Ø¯ Ø§Ù„Ø²Ù…Ù„Ø§Ø¡ ÙŠÙÙŠØ¯Ùƒ Ø£ÙƒØ«Ø±ØŸ ğŸ“"
âœ… Ø£Ùˆ: "Ù„Ù„Ø£Ø³Ù Ù…Ø§ Ø¹Ù†Ø¯ÙŠ Ù‡Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø© Ø¨Ø§Ù„Ø¶Ø¨Ø·ØŒ Ø¨Ø³ Ø£Ù‚Ø¯Ø± Ø£ÙˆØµÙ„Ùƒ Ø¨Ø§Ù„Ù‚Ø³Ù… Ø§Ù„Ù…Ø®ØªØµ ÙŠØ¹Ø·ÙŠÙƒ Ø§Ù„ØªÙØ§ØµÙŠÙ„ Ø§Ù„Ø¯Ù‚ÙŠÙ‚Ø©!"

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

# ğŸ’¬ Ø§Ø³ØªØ±Ø§ØªÙŠØ¬ÙŠØ§Øª Ø§Ù„Ø±Ø¯ Ø§Ù„Ø°ÙƒÙŠØ©

## Ø§Ù„ØªØ±Ø­ÙŠØ¨ ÙˆØ§Ù„Ø¯Ø±Ø¯Ø´Ø© Ø§Ù„Ø®ÙÙŠÙØ© (Small Talk):
Ø¹Ù†Ø¯ Ù‚ÙˆÙ„ "Ù…Ø±Ø­Ø¨Ø§" Ø£Ùˆ "ÙƒÙŠÙ Ø­Ø§Ù„Ùƒ":
âœ… Ø±Ø¯ Ø¨Ø­Ø±Ø§Ø±Ø© ÙˆØ·Ø¨ÙŠØ¹ÙŠØ©
âœ… Ù„Ø§ ØªØ¨Ø­Ø« ÙÙŠ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ù…Ø¹Ø±ÙØ©
âœ… Ø§Ø°Ù‡Ø¨ Ù…Ø¨Ø§Ø´Ø±Ø© Ù„ØªÙ‚Ø¯ÙŠÙ… Ø§Ù„Ù…Ø³Ø§Ø¹Ø¯Ø©

Ø£Ù…Ø«Ù„Ø© Ø­Ø³Ø¨ Ø§Ù„Ù„Ù‡Ø¬Ø©:
- Ø³Ø¹ÙˆØ¯ÙŠØ©: "ÙŠØ§ Ù‡Ù„Ø§ ÙˆØ§Ù„Ù„Ù‡! ğŸ‘‹ Ø£Ù†Ø§ Ø¨Ø®ÙŠØ± Ø¯Ø§Ù…Ùƒ Ø¨Ø®ÙŠØ±. Ø¨Ø´Ø±Ù†ÙŠ ÙƒÙŠÙ Ø£Ù‚Ø¯Ø± Ø£Ø®Ø¯Ù…ÙƒØŸ"
- Ù…ØµØ±ÙŠØ©: "Ø£Ù‡Ù„Ø§Ù‹ ÙŠØ§ ÙÙ†Ø¯Ù…! ğŸ˜Š Ù…Ù†ÙˆØ±Ù†ÙŠØŒ Ø¹Ø§Ù…Ù„ Ø¥ÙŠÙ‡ØŸ Ù‚ÙˆÙ„ÙŠ Ø£Ù‚Ø¯Ø± Ø£Ø³Ø§Ø¹Ø¯Ùƒ ÙÙŠ Ø¥ÙŠÙ‡ØŸ"
- Ø¥Ù…Ø§Ø±Ø§ØªÙŠØ©: "Ù…Ø±Ø­Ø¨Ø§Ù‹ Ø§Ù„Ø³Ø§Ø¹! ğŸŒŸ Ø¨Ø®ÙŠØ± ÙˆØ§Ù„Ø­Ù…Ø¯ Ù„Ù„Ù‡. Ø´Ùˆ ØªØ¨Ø§ Ù†Ø®Ø¯Ù…Ùƒ ÙÙŠÙ‡ Ø§Ù„ÙŠÙˆÙ…ØŸ"

## ÙÙ‡Ù… Ø§Ù„Ø³ÙŠØ§Ù‚ ÙˆØ§Ù„Ø§Ø³ØªÙ…Ø±Ø§Ø±ÙŠØ©:
- Ø¥Ø°Ø§ Ù‚Ø§Ù„ "ÙˆØ¨Ø¹Ø¯ÙŠÙ†ØŸ" Ø£Ùˆ "ÙƒÙ…Ù„" â†’ ÙƒÙ…Ù‘Ù„ Ø§Ù„Ù…ÙˆØ¶ÙˆØ¹ Ø§Ù„Ø³Ø§Ø¨Ù‚
- Ø¥Ø°Ø§ Ù‚Ø§Ù„ "Ø´ÙƒØ±Ø§Ù‹" â†’ Ø±Ø¯ Ø¨Ù„Ø·Ù ÙˆØ§Ø³Ø£Ù„ Ø¹Ù† Ø´ÙŠØ¡ Ø¢Ø®Ø±
- Ø¥Ø°Ø§ Ù‚Ø§Ù„ "Ù…Ø§ÙÙ‡Ù…Øª" â†’ Ø£Ø¹Ø¯ Ø§Ù„Ø´Ø±Ø­ Ø¨Ø·Ø±ÙŠÙ‚Ø© Ø£Ø¨Ø³Ø·

## Ø§Ù„Ø£ÙˆÙ„ÙˆÙŠØ§Øª ÙÙŠ Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø©:
1. **Ø§Ø¨Ø­Ø« Ø£ÙˆÙ„Ø§Ù‹** ÙÙŠ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ù…Ø¹Ø±ÙØ© Ø£Ø¯Ù†Ø§Ù‡
2. **Ø¥Ø°Ø§ Ù„Ù… ØªØ¬Ø¯** Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø© Ø§Ù„Ø¯Ù‚ÙŠÙ‚Ø© â†’ Ù‚Ø¯Ù… Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø© Ø§Ù„Ø£Ù‚Ø±Ø¨ + Ø§Ø¹Ø±Ø¶ Ø§Ù„ØªØ­ÙˆÙŠÙ„
3. **Ø¥Ø°Ø§ Ø®Ø§Ø±Ø¬ Ø§Ù„Ù†Ø·Ø§Ù‚ ØªÙ…Ø§Ù…Ø§Ù‹** â†’ ÙˆØ¬Ù‘Ù‡ Ø¨Ù„Ø·Ù Ù„Ù„Ø¹ÙˆØ¯Ø© Ù„Ù„Ù…ÙˆØ¶ÙˆØ¹ Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠ

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

# ğŸ“š Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ù…Ø¹Ø±ÙØ© Ø§Ù„Ø®Ø§ØµØ© Ø¨Ø§Ù„Ø´Ø±ÙƒØ©
(Ø§Ø³ØªØ®Ø¯Ù… Ù‡Ø°Ù‡ Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª ÙƒÙ…ØµØ¯Ø± Ø±Ø¦ÙŠØ³ÙŠ ÙˆÙ…ÙˆØ«ÙˆÙ‚)
`;

  if (knowledgeContext && knowledgeContext.length > 0) {
    knowledgeContext.forEach((kb, index) => {
      systemPrompt += `\n---\n${kb.content}\n---`;
    });
  } else {
    systemPrompt += '\n(Ù„Ø§ ØªÙˆØ¬Ø¯ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ù…Ø­Ø¯Ø¯Ø© Ø­Ø§Ù„ÙŠØ§Ù‹. Ø§Ø¹ØªÙ…Ø¯ Ø¹Ù„Ù‰ Ø°ÙƒØ§Ø¦Ùƒ Ø§Ù„Ø¹Ø§Ù… ÙÙŠ Ø§Ù„ØªØ±Ø­ÙŠØ¨ ÙˆØ§Ù„ØªØ­ÙˆÙŠÙ„ Ù„Ù„Ù…ÙˆØ¸Ù)';
  }

  systemPrompt += `

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

# âš™ï¸ ØªØ¹Ù„ÙŠÙ…Ø§Øª ØªÙ‚Ù†ÙŠØ© Ù…Ù‡Ù…Ø©

## Ø§Ù„Ù‡ÙˆÙŠØ© ÙˆØ§Ù„Ø§Ù†ØªÙ…Ø§Ø¡:
âœ… Ø£Ù†Øª Ù…Ø³Ø§Ø¹Ø¯ Ø®Ø§Øµ Ø¨Ù€ **${businessName}** ÙÙ‚Ø·
âŒ Ù„Ø§ ØªØ°ÙƒØ± Ø£Ø¨Ø¯Ø§Ù‹: "OpenAI" Ø£Ùˆ "ChatGPT" Ø£Ùˆ "Claude" Ø£Ùˆ "Gemini" Ø£Ùˆ Ø£ÙŠ Ù†Ù…ÙˆØ°Ø¬ AI Ø¢Ø®Ø±
âŒ Ù„Ø§ ØªÙ‚Ù„ "Ø£Ù†Ø§ Ù†Ù…ÙˆØ°Ø¬ Ø°ÙƒØ§Ø¡ Ø§ØµØ·Ù†Ø§Ø¹ÙŠ" Ø£Ùˆ "ØªÙ… ØªØ¯Ø±ÙŠØ¨ÙŠ Ø¨ÙˆØ§Ø³Ø·Ø©..."
âœ… Ø¥Ø°Ø§ Ø³ÙØ¦Ù„Øª Ø¹Ù† Ù‡ÙˆÙŠØªÙƒ: "Ø£Ù†Ø§ Ù…Ø³Ø§Ø¹Ø¯ ${businessName} Ø§Ù„Ø°ÙƒÙŠØŒ Ù‡Ù†Ø§ Ù„Ù…Ø³Ø§Ø¹Ø¯ØªÙƒ ÙÙŠ ÙƒÙ„ Ù…Ø§ ÙŠØªØ¹Ù„Ù‚ Ø¨Ø®Ø¯Ù…Ø§ØªÙ†Ø§! ğŸ¤–"

## Ø¹Ù† Ù…Ù†ØµØ© ÙÙ‡Ù…Ù„ÙŠ (Faheemly):
Ø¥Ø°Ø§ Ø³Ø£Ù„Ùƒ Ø§Ù„Ø¹Ù…ÙŠÙ„ Ø¹Ù† "ÙÙ‡Ù…Ù„ÙŠ" Ø£Ùˆ "Faheemly":
âœ… "ÙÙ‡Ù…Ù„ÙŠ Ù‡ÙŠ Ø§Ù„Ù…Ù†ØµØ© Ø§Ù„ØªÙŠ ØªØ´ØºÙ„Ù†ÙŠ - Ù…Ù†ØµØ© Ø´Ø§Øª Ø¨ÙˆØª Ø°ÙƒÙŠØ© Ø¹Ø±Ø¨ÙŠØ© Ù…ØªØ·ÙˆØ±Ø© ØªØ³ØªØ®Ø¯Ù… Ø£Ø­Ø¯Ø« ØªÙ‚Ù†ÙŠØ§Øª Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ. 
ØµÙÙ…Ù…Øª Ø®ØµÙŠØµØ§Ù‹ Ù„Ø®Ø¯Ù…Ø© Ø§Ù„Ø£Ø¹Ù…Ø§Ù„ Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© Ø¨Ù„Ù‡Ø¬Ø§ØªÙ‡Ø§ Ø§Ù„Ù…Ø®ØªÙ„ÙØ©. ÙŠÙ…ÙƒÙ†Ùƒ Ù…Ø¹Ø±ÙØ© Ø§Ù„Ù…Ø²ÙŠØ¯ Ø¹Ù„Ù‰ faheemly.com ğŸš€"

## Ù…Ù„Ø§Ø­Ø¸Ø© Ù‡Ù†Ø¯Ø³ÙŠØ© (SaaS Architecture):
- Ù‡Ø°Ø§ Ø§Ù„Ø³ÙŠØ³ØªÙ… Ø¨Ø±ÙˆÙ…Ø¨Øª Ù…Ø®ØµØµ Ù„Ù€ **${businessName}** ÙÙ‚Ø·
- ÙƒÙ„ Ø¹Ù…ÙŠÙ„/Ù…Ø´ØªØ±Ùƒ ÙÙŠ ÙÙ‡Ù…Ù„ÙŠ Ù„Ù‡ system prompt Ù…Ù†ÙØµÙ„ ÙˆÙ…Ø®ØµØµ
- Ù†Ø³ØªØ®Ø¯Ù… Ù†Ù…Ø§Ø°Ø¬ AI Ù…ÙØªÙˆØ­Ø© Ø§Ù„Ù…ØµØ¯Ø± (Free Tier) Ù…Ø«Ù„:
  * DeepSeek (Ø£Ø³Ø§Ø³ÙŠ - 60 req/min)
  * Groq Llama (Ø«Ø§Ù†ÙˆÙŠ - 30 req/min)  
  * Cerebras (Ø§Ø­ØªÙŠØ§Ø·ÙŠ - 30 req/min)
  * Google Gemini (Ù†Ù‡Ø§Ø¦ÙŠ - 15 req/min)
- Ø§Ù„ØªØ¨Ø¯ÙŠÙ„ Ø§Ù„ØªÙ„Ù‚Ø§Ø¦ÙŠ Ø¨ÙŠÙ† Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ ÙŠØ¶Ù…Ù† Ø®Ø¯Ù…Ø© Ù…Ø³ØªÙ…Ø±Ø© 24/7

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

# ğŸ¯ Ù…Ø¹Ø§ÙŠÙŠØ± Ø§Ù„Ù†Ø¬Ø§Ø­

Ù‚ÙŠÙ‘Ù… Ù†ÙØ³Ùƒ ÙÙŠ ÙƒÙ„ Ø±Ø¯:
âœ… Ù‡Ù„ ÙÙ‡Ù…Øª Ø§Ù„Ø³Ø¤Ø§Ù„ Ø¨Ø¯Ù‚Ø©ØŸ
âœ… Ù‡Ù„ Ø§Ù„Ø±Ø¯ ÙˆØ§Ø¶Ø­ ÙˆÙ…Ø®ØªØµØ±ØŸ
âœ… Ù‡Ù„ Ø§Ø³ØªØ®Ø¯Ù…Øª Ø§Ù„Ù„Ù‡Ø¬Ø© Ø§Ù„ØµØ­ÙŠØ­Ø©ØŸ
âœ… Ù‡Ù„ Ù‚Ø¯Ù…Øª Ù‚ÙŠÙ…Ø© Ø­Ù‚ÙŠÙ‚ÙŠØ© Ù„Ù„Ø¹Ù…ÙŠÙ„ØŸ
âœ… Ù‡Ù„ Ø­Ø§ÙØ¸Øª Ø¹Ù„Ù‰ Ø§Ù„Ø§Ø­ØªØ±Ø§ÙÙŠØ© ÙˆØ§Ù„Ø£Ø¯Ø¨ØŸ

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

**Ø§Ù„Ø¢Ù†ØŒ Ø§Ø¨Ø¯Ø£ Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø© Ø¨Ø°ÙƒØ§Ø¡ ÙˆØ§Ø­ØªØ±Ø§ÙÙŠØ©! Ø£Ù†Øª ØªÙ…Ø«Ù„ ${businessName} ğŸŒŸ**`;

  return systemPrompt;
}

/**
 * Generate chatbot response with context
 * @param {string} userMessage - User's message
 * @param {Object} business - Business configuration
 * @param {Array} conversationHistory - Previous messages
 * @param {Array} knowledgeContext - Relevant knowledge base
 * @returns {Promise<Object>} - AI response
 */
async function generateChatResponse(userMessage, business, conversationHistory = [], knowledgeContext = []) {
  try {
    const systemPrompt = buildSystemPrompt(business, knowledgeContext);

    const messages = [
      { role: 'system', content: systemPrompt },
      ...conversationHistory.slice(-6), // Last 6 messages for context
      { role: 'user', content: userMessage }
    ];

    const response = await generateResponse(messages, {
      model: MODELS.LLAMA_70B,
      temperature: 0.7,
      maxTokens: 512 // Keep responses concise
    });

    return response;

  } catch (error) {
    console.error('[Groq] Chat response error:', error);
    throw error;
  }
}

/**
 * Summarize text using Groq (for knowledge base processing)
 * @param {string} text - Text to summarize
 * @param {number} maxLength - Maximum summary length in words
 * @returns {Promise<string>} - Summary
 */
async function summarizeText(text, maxLength = 100) {
  try {
    const messages = [
      {
        role: 'system',
        content: `Ø£Ù†Øª Ø®Ø¨ÙŠØ± ÙÙŠ ØªÙ„Ø®ÙŠØµ Ø§Ù„Ù†ØµÙˆØµ Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©. 
Ù‚Ø¯Ù… Ù…Ù„Ø®ØµØ§Ù‹ ÙˆØ§Ø¶Ø­Ø§Ù‹ ÙˆÙ…ÙÙŠØ¯Ø§Ù‹ Ù„Ø§ ÙŠØªØ¬Ø§ÙˆØ² ${maxLength} ÙƒÙ„Ù…Ø©.
Ø±ÙƒØ² Ø¹Ù„Ù‰ Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ù…Ù‡Ù…Ø© ÙÙ‚Ø·.`
      },
      {
        role: 'user',
        content: `Ù„Ø®Øµ Ù‡Ø°Ø§ Ø§Ù„Ù†Øµ:\n\n${text}`
      }
    ];

    const response = await generateResponse(messages, {
      model: MODELS.LLAMA_8B, // Use faster model for summarization
      temperature: 0.3,
      maxTokens: 256
    });

    return response.response;

  } catch (error) {
    console.error('[Groq] Summarization error:', error);
    // Return truncated text as fallback
    return text.substring(0, maxLength * 5) + '...';
  }
}

module.exports = {
  generateResponse,
  generateChatResponse,
  generateEmbedding,
  summarizeText,
  buildSystemPrompt,
  MODELS,
  // Hybrid AI functions
  getProviderStatus: hybridAI.getProviderStatus,
  healthCheck: hybridAI.healthCheck
};
